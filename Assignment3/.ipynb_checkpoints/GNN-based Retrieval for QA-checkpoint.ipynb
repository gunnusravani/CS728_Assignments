{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a04abd-d4fd-4e23-a399-8da8bd7bed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "train_df = pd.read_json(\"./Data/train.json\")\n",
    "test_df = pd.read_json(\"./Data/test.json\")\n",
    "val_df = pd.read_json(\"./Data/dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867629a8-57d9-4646-bf53-accc53b561ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc2cd08-1c56-428e-956d-a20ceb75de2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing device: cpu\n",
      "Main computation device: cuda\n",
      "Train samples: 167454\n",
      "Val samples: 12576\n",
      "Test samples: 12576\n",
      "Number of passages: 10\n",
      "Number of edges: 13\n",
      "Edge type distribution: {'sequential': 9, 'keyword': 4}\n",
      "Building train dataset:\n",
      "Processing chunk 0-50 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 0-50: 100%|████████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 50-100 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 50-100: 100%|██████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 100-150 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 100-150: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 150-200 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 150-200: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 200-250 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 200-250: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:10<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 250-300 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 250-300: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 300-350 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 300-350: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 350-400 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 350-400: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 400-450 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 400-450: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 450-500 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 450-500: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 500-550 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 500-550: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 550-600 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 550-600: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 600-650 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 600-650: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 650-700 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 650-700: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 700-750 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 700-750: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 750-800 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 750-800: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 800-850 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 800-850: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 850-900 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 850-900: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 900-950 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 900-950: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:10<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 950-1000 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 950-1000: 100%|████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset to train_dataset_large.pkl\n",
      "Building val dataset:\n",
      "Processing chunk 0-50 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 0-50: 100%|████████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 50-100 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 50-100: 100%|██████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 100-150 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 100-150: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 150-200 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 150-200: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 200-250 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 200-250: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 250-300 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 250-300: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset to val_dataset_large.pkl\n",
      "Building test dataset:\n",
      "Processing chunk 0-50 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 0-50: 100%|████████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 50-100 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 50-100: 100%|██████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 100-150 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 100-150: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 150-200 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 150-200: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 200-250 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 200-250: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 250-300 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 250-300: 100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  5.58it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset to test_dataset_large.pkl\n",
      "\n",
      "Dataset sizes:\n",
      "Train: 1000 examples\n",
      "Validation: 300 examples\n",
      "Test: 300 examples\n",
      "\n",
      "==================================================\n",
      "Training with MEAN aggregation\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 21.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 1.7457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 143.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7399, F1: 0.5026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 21.30it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Train Loss: 1.1513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 145.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7700, F1: 0.5201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 22.24it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Train Loss: 0.8507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 144.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7854, F1: 0.5392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 21.63it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Train Loss: 0.6231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 148.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7856, F1: 0.5363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 22.73it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train Loss: 0.4703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 146.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.8098, F1: 0.5419\n",
      "\n",
      "==================================================\n",
      "Training with MAX aggregation\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 20.89it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 1.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 155.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7105, F1: 0.5042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 21.57it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Train Loss: 1.1573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 159.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7402, F1: 0.5073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:06<00:00, 20.57it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Train Loss: 0.8717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 159.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7809, F1: 0.5228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 20.89it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Train Loss: 0.6810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 158.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7852, F1: 0.5266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 21.81it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train Loss: 0.5136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 159.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7890, F1: 0.5283\n",
      "\n",
      "==================================================\n",
      "Training with SUM aggregation\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:06<00:00, 20.80it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 1.7908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 164.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.6943, F1: 0.4996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 21.39it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Train Loss: 1.1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 159.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7414, F1: 0.5017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 21.76it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Train Loss: 0.8751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 157.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7464, F1: 0.5307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 20.93it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Train Loss: 0.6797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 151.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7609, F1: 0.5264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 21.71it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train Loss: 0.5206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 166.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7611, F1: 0.5345\n",
      "\n",
      "==================================================\n",
      "Training with MIN aggregation\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 22.58it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 1.8210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 164.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7244, F1: 0.4954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 22.63it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Train Loss: 1.1838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 164.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7611, F1: 0.5207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 22.54it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Train Loss: 0.8797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 163.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.7883, F1: 0.5293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 22.46it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Train Loss: 0.7034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 125.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.8080, F1: 0.5310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Training batches: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 22.57it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train Loss: 0.5499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 163.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - MRR: 0.8252, F1: 0.5422\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregation Function Comparison:\n",
      "================================\n",
      "Aggregation  MRR        F1        \n",
      "--------------------------------\n",
      "MEAN         0.8098     0.5419\n",
      "MAX          0.7890     0.5283\n",
      "SUM          0.7611     0.5345\n",
      "MIN          0.8252     0.5422\n",
      "\n",
      "Best for MRR: MIN\n",
      "Best for F1: MIN\n",
      "Best aggregation function by MRR: MIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  23%|████████████████                                                       | 17/75 [00:00<00:00, 160.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1:\n",
      "  Question: [Hidden for brevity]\n",
      "  Predictions: ['Dell Henderson', 'One Law for Both', 'One Law for the Woman', 'Inez Mee Boren', 'John Donatich']\n",
      "  Ground truth: []\n",
      "  Overlap: set()\n",
      "\n",
      "Example 2:\n",
      "  Question: [Hidden for brevity]\n",
      "  Predictions: ['Ralph Murphy', 'Panama Flo', 'Liz in September', 'Fina Torres', 'Yolonda Ross']\n",
      "  Ground truth: []\n",
      "  Overlap: set()\n",
      "\n",
      "Example 3:\n",
      "  Question: [Hidden for brevity]\n",
      "  Predictions: ['Alexander Comyn, Earl of Buchan', 'Alexander Stewart, Earl of Buchan', 'Robert de Moravia, 6th Earl of Sutherland', 'John de Innes', 'Jardine Comyn']\n",
      "  Ground truth: []\n",
      "  Overlap: set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 163.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation statistics:\n",
      "  Total examples evaluated: 300\n",
      "  Examples with at least one correct prediction: 0\n",
      "  Percentage with correct predictions: 0.00%\n",
      "\n",
      "=== Final Test Results with MIN Aggregation ===\n",
      "Test MRR: 0.0000\n",
      "Test F1: 0.0000\n",
      "\n",
      "Running baseline evaluations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating BM25: 100%|███████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 1280.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Results (k=5):\n",
      "  MRR: 0.0000\n",
      "  F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DPR: 100%|██████████████████████████████████████████████████████████████████| 300/300 [00:47<00:00,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Retrieval Results (k=5):\n",
      "  MRR: 0.0000\n",
      "  F1: 0.0000\n",
      "\n",
      "Retrieval Model Comparison:\n",
      "             Model  MRR   F1\n",
      "0             BM25  0.0  0.0\n",
      "1  Dense Retrieval  0.0  0.0\n",
      "2        GNN (MIN)  0.0  0.0\n",
      "Results saved to model_comparison_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "# Set memory management parameters\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Detect device - default to CPU for preprocessing to avoid memory issues\n",
    "preprocess_device = \"cpu\"  # Use CPU for preprocessing\n",
    "main_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Preprocessing device: {preprocess_device}\")\n",
    "print(f\"Main computation device: {main_device}\")\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_json(\"./Data/train.json\")\n",
    "test_df = pd.read_json(\"./Data/test.json\")\n",
    "val_df = pd.read_json(\"./Data/dev.json\")\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Val samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "# --- Memory-Optimized Graph Construction ---\n",
    "def build_graph_of_passages(context, similarity_threshold=0.7, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Memory-optimized graph construction with multiple edge types\n",
    "    \n",
    "    Args:\n",
    "        context: List of [title, text] pairs\n",
    "        similarity_threshold: Threshold for semantic similarity edges\n",
    "        device: Device to use for computation\n",
    "        \n",
    "    Returns: \n",
    "        G: NetworkX graph\n",
    "        embeddings: Passage embeddings tensor\n",
    "        titles: List of passage titles\n",
    "    \"\"\"\n",
    "    # Use a lighter model to avoid memory issues\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    G = nx.Graph()\n",
    "    titles = [title for title, _ in context]\n",
    "    texts = [\" \".join(text) if isinstance(text, list) else text for _, text in context]\n",
    "\n",
    "    # Add nodes\n",
    "    for title in titles:\n",
    "        G.add_node(title)\n",
    "\n",
    "    # Process embeddings in batches to reduce memory usage\n",
    "    batch_size = 16\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model.encode(batch_texts, convert_to_tensor=True, device=device)\n",
    "            # Move embeddings to CPU immediately to free GPU memory\n",
    "            all_embeddings.append(batch_embeddings.cpu())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    \n",
    "    # Clear CUDA cache to free memory\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Add sequential edges (document order)\n",
    "    for i in range(len(titles) - 1):\n",
    "        G.add_edge(titles[i], titles[i + 1], weight=1.0, type=\"sequential\")\n",
    "    \n",
    "    # Add semantic similarity edges - process in batches\n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i + 1, len(titles)):\n",
    "            score = util.pytorch_cos_sim(embeddings[i], embeddings[j]).item()\n",
    "            if score > similarity_threshold:\n",
    "                G.add_edge(titles[i], titles[j], weight=score, type=\"semantic\")\n",
    "    \n",
    "    # Add keyword-based edges\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    try:\n",
    "        X = vectorizer.fit_transform(texts)\n",
    "        \n",
    "        for i in range(len(titles)):\n",
    "            X_i = X[i].toarray().flatten()\n",
    "            for j in range(i + 1, len(titles)):\n",
    "                # Only compute for pairs that don't have edges yet\n",
    "                if not G.has_edge(titles[i], titles[j]):\n",
    "                    X_j = X[j].toarray().flatten()\n",
    "                    intersection = np.logical_and(X_i, X_j).sum()\n",
    "                    union = np.logical_or(X_i, X_j).sum()\n",
    "                    if union > 0 and intersection/union > 0.2:  # At least 20% keyword overlap\n",
    "                        G.add_edge(titles[i], titles[j], weight=intersection/union, type=\"keyword\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Keyword edge creation failed: {e}. Continuing without keyword edges.\")\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    return G, embeddings, titles\n",
    "\n",
    "# Test the graph construction\n",
    "context = train_df.iloc[0]['context']\n",
    "context_pairs = [tuple(x) for x in context]\n",
    "G, embs, titles = build_graph_of_passages(context_pairs)\n",
    "\n",
    "# Print graph statistics\n",
    "edge_types = {}\n",
    "for u, v, data in G.edges(data=True):\n",
    "    edge_type = data.get('type', 'unknown')\n",
    "    edge_types[edge_type] = edge_types.get(edge_type, 0) + 1\n",
    "\n",
    "print(f\"Number of passages: {len(titles)}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "print(f\"Edge type distribution: {edge_types}\")\n",
    "\n",
    "# --- PyG Data Conversion ---\n",
    "def convert_to_pyg_data(G, embeddings, titles):\n",
    "    \"\"\"\n",
    "    Convert NetworkX graph to PyTorch Geometric format.\n",
    "    \n",
    "    Args:\n",
    "        G: NetworkX graph\n",
    "        embeddings: Node feature tensor\n",
    "        titles: List of node names\n",
    "        \n",
    "    Returns:\n",
    "        PyG Data object\n",
    "    \"\"\"\n",
    "    # Assign node features\n",
    "    for i, title in enumerate(titles):\n",
    "        G.nodes[title]['x'] = embeddings[i]\n",
    "\n",
    "    # Convert to PyG graph\n",
    "    pyg_graph = from_networkx(G)\n",
    "    pyg_graph.x = torch.stack([G.nodes[t]['x'] for t in titles])\n",
    "    \n",
    "    # Store original titles for reference\n",
    "    pyg_graph.titles = titles\n",
    "    \n",
    "    return pyg_graph\n",
    "\n",
    "# --- GNN Model with Different Aggregations ---\n",
    "class ImprovedPassageGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout=0.2, aggregation='mean'):\n",
    "        \"\"\"\n",
    "        Enhanced GNN for passage representation learning with configurable aggregation\n",
    "        \n",
    "        Args:\n",
    "            in_channels: Input feature dimensions\n",
    "            hidden_channels: Hidden layer dimensions\n",
    "            out_channels: Output feature dimensions\n",
    "            num_layers: Number of GNN layers\n",
    "            dropout: Dropout rate\n",
    "            aggregation: Aggregation function ('mean', 'max', 'sum', or 'min')\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.aggregation = aggregation\n",
    "        \n",
    "        # Multiple conv layers with normalization\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "        \n",
    "        # First layer\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels, aggr=aggregation))\n",
    "        self.norms.append(torch.nn.LayerNorm(hidden_channels))\n",
    "        \n",
    "        # Hidden layers with residual connections\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels, aggr=aggregation))\n",
    "            self.norms.append(torch.nn.LayerNorm(hidden_channels))\n",
    "            \n",
    "        # Output layer\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels, aggr=aggregation))\n",
    "        \n",
    "        # Final projection layer\n",
    "        self.final_projection = nn.Sequential(\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"Forward pass with residual connections\"\"\"\n",
    "        # Initial features\n",
    "        h = x\n",
    "        \n",
    "        # Apply GNN layers with residual connections\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            # Main conv operation\n",
    "            h_new = conv(h, edge_index)\n",
    "            h_new = self.norms[i](h_new)\n",
    "            h_new = F.relu(h_new)\n",
    "            h_new = F.dropout(h_new, p=self.dropout, training=self.training)\n",
    "            \n",
    "            # Add residual connection if shapes match\n",
    "            if h.shape[-1] == h_new.shape[-1]:\n",
    "                h = h + h_new\n",
    "            else:\n",
    "                h = h_new\n",
    "                \n",
    "        # Final layer without activation\n",
    "        h = self.convs[-1](h, edge_index)\n",
    "        \n",
    "        # Final projection\n",
    "        h = self.final_projection(h)\n",
    "        \n",
    "        return h\n",
    "\n",
    "# --- Cached Embedder for Memory Efficiency ---\n",
    "class CachedEmbedder:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', device=\"cpu\"):\n",
    "        \"\"\"Initialize with a lighter model and specific device\"\"\"\n",
    "        self.model = SentenceTransformer(model_name).to(device)\n",
    "        self.device = device\n",
    "        self.passage_cache = {}\n",
    "        self.question_cache = {}\n",
    "\n",
    "    def encode_passages(self, texts, batch_size=16):\n",
    "        \"\"\"Encode passages with batching and caching\"\"\"\n",
    "        to_encode = [t for t in texts if t not in self.passage_cache]\n",
    "        \n",
    "        if to_encode:\n",
    "            # Process in batches\n",
    "            all_embeddings = []\n",
    "            for i in range(0, len(to_encode), batch_size):\n",
    "                batch_texts = to_encode[i:i+batch_size]\n",
    "                with torch.no_grad():\n",
    "                    batch_embs = self.model.encode(batch_texts, convert_to_tensor=True, device=self.device)\n",
    "                    all_embeddings.append(batch_embs.cpu())  # Move to CPU to save GPU memory\n",
    "                    \n",
    "                    # Clear CUDA cache after each batch\n",
    "                    if self.device == \"cuda\":\n",
    "                        torch.cuda.empty_cache()\n",
    "            \n",
    "            # Process and store embeddings\n",
    "            if all_embeddings:\n",
    "                all_embs = torch.cat(all_embeddings, dim=0)\n",
    "                for text, emb in zip(to_encode, all_embs):\n",
    "                    self.passage_cache[text] = emb\n",
    "        \n",
    "        # Return embeddings from cache\n",
    "        return [self.passage_cache[t] for t in texts]\n",
    "\n",
    "    def encode_question(self, question):\n",
    "        \"\"\"Encode question with caching\"\"\"\n",
    "        if question not in self.question_cache:\n",
    "            with torch.no_grad():\n",
    "                self.question_cache[question] = self.model.encode(\n",
    "                    question, convert_to_tensor=True, device=self.device).cpu()\n",
    "        return self.question_cache[question]\n",
    "\n",
    "# --- Memory-Efficient Dataset Creation ---\n",
    "def create_graph_data(question, context, supporting_titles, embedder, device=\"cpu\"):\n",
    "    \"\"\"Create a graph with batched processing to reduce memory usage\"\"\"\n",
    "    try:\n",
    "        titles = [title for title, _ in context]\n",
    "        texts = [\" \".join(text) if isinstance(text, list) else text for _, text in context]\n",
    "        \n",
    "        # Use the cached embedder for batched processing\n",
    "        embeddings = embedder.encode_passages(texts)\n",
    "\n",
    "        # Create graph\n",
    "        G = nx.Graph()\n",
    "        for i, title in enumerate(titles):\n",
    "            G.add_node(title, x=embeddings[i])\n",
    "            \n",
    "        # Add sequential edges\n",
    "        for i in range(len(titles) - 1):\n",
    "            G.add_edge(titles[i], titles[i + 1], weight=1.0, type=\"sequential\")\n",
    "\n",
    "        # Add semantic edges - process in batches\n",
    "        for i in range(len(titles)):\n",
    "            for j in range(i + 1, len(titles)):\n",
    "                sim = util.pytorch_cos_sim(embeddings[i], embeddings[j]).item()\n",
    "                if sim > 0.7:\n",
    "                    G.add_edge(titles[i], titles[j], weight=sim, type=\"semantic\")\n",
    "                        \n",
    "        # Add keyword edges\n",
    "        try:\n",
    "            vectorizer = CountVectorizer(stop_words='english')\n",
    "            X = vectorizer.fit_transform([\" \".join(text) if isinstance(text, list) else text for _, text in context])\n",
    "            \n",
    "            for i in range(len(titles)):\n",
    "                X_i = X[i].toarray().flatten()\n",
    "                for j in range(i + 1, len(titles)):\n",
    "                    if not G.has_edge(titles[i], titles[j]):\n",
    "                        X_j = X[j].toarray().flatten()\n",
    "                        intersection = np.logical_and(X_i, X_j).sum()\n",
    "                        union = np.logical_or(X_i, X_j).sum()\n",
    "                        if union > 0 and intersection/union > 0.2:\n",
    "                            G.add_edge(titles[i], titles[j], weight=intersection/union, type=\"keyword\")\n",
    "        except Exception as e:\n",
    "            print(f\"Keyword edge creation failed: {e}\")\n",
    "\n",
    "        # Convert to PyG format\n",
    "        pyg_graph = from_networkx(G)\n",
    "        pyg_graph.x = torch.stack([G.nodes[t]['x'] for t in titles])\n",
    "        pyg_graph.titles = titles\n",
    "        pyg_graph.supporting_titles = supporting_titles\n",
    "        pyg_graph.question_embedding = embedder.encode_question(question)\n",
    "\n",
    "        return pyg_graph\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating graph: {e}\")\n",
    "        return None\n",
    "\n",
    "def build_dataset(df, embedder, max_samples=None, save_path=None, load_path=None, chunk_size=25):\n",
    "    \"\"\"\n",
    "    Build dataset with memory-efficient chunking\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with examples\n",
    "        embedder: CachedEmbedder instance\n",
    "        max_samples: Maximum number of samples to process\n",
    "        save_path: Path to save the dataset\n",
    "        load_path: Path to load a pre-existing dataset\n",
    "        chunk_size: Number of examples to process in a chunk\n",
    "    \"\"\"\n",
    "    if load_path and os.path.exists(load_path):\n",
    "        try:\n",
    "            with open(load_path, 'rb') as f:\n",
    "                print(f\"Loaded dataset from {load_path}\")\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dataset: {e}\")\n",
    "    \n",
    "    # Apply sample limit if specified\n",
    "    if max_samples:\n",
    "        df = df.iloc[:max_samples]\n",
    "    \n",
    "    dataset = []\n",
    "    temp_path = f\"{save_path}.temp\" if save_path else None\n",
    "    \n",
    "    dataset_type = save_path.split('_')[0] if save_path else \"unknown\"\n",
    "    print(f\"Building {dataset_type} dataset:\")\n",
    "    \n",
    "    # Process in chunks to manage memory better\n",
    "    for chunk_start in range(0, len(df), chunk_size):\n",
    "        chunk_end = min(chunk_start + chunk_size, len(df))\n",
    "        print(f\"Processing chunk {chunk_start}-{chunk_end} of {len(df)}\")\n",
    "        \n",
    "        chunk_data = []\n",
    "        for idx, row in tqdm(df.iloc[chunk_start:chunk_end].iterrows(), \n",
    "                            total=chunk_end-chunk_start, \n",
    "                            desc=f\"Chunk {chunk_start}-{chunk_end}\"):\n",
    "            try:\n",
    "                question = row['question']\n",
    "                context = [tuple(x) for x in row['context']]\n",
    "                supporting = [x[0] for x in row['supporting_facts']]\n",
    "                \n",
    "                # Create graph for this example\n",
    "                graph = create_graph_data(question, context, supporting, embedder)\n",
    "                if graph:\n",
    "                    chunk_data.append(graph)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Add chunk data to dataset\n",
    "        dataset.extend(chunk_data)\n",
    "        \n",
    "        # Save intermediate results\n",
    "        if temp_path:\n",
    "            with open(f\"{temp_path}_{chunk_start}\", 'wb') as f:\n",
    "                pickle.dump(dataset, f)\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Save final dataset\n",
    "    if save_path:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(dataset, f)\n",
    "        print(f\"Saved dataset to {save_path}\")\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# --- Training and Evaluation Functions ---\n",
    "def train_gnn_batch(loader, gnn_model, optimizer, margin=0.2, device=None):\n",
    "    \"\"\"\n",
    "    Enhanced training function with margin ranking loss\n",
    "    \n",
    "    Args:\n",
    "        loader: DataLoader for training\n",
    "        gnn_model: GNN model\n",
    "        optimizer: Optimizer\n",
    "        margin: Margin for ranking loss\n",
    "        device: Device to use\n",
    "        \n",
    "    Returns:\n",
    "        Average training loss\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    gnn_model.train()\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for batch in tqdm(loader, desc=\"Training batches\"):\n",
    "        # Move batch to device\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Get question embeddings and title lists\n",
    "        q_embs = []\n",
    "        titles_batch = []\n",
    "        supporting_batch = []\n",
    "        \n",
    "        for data in batch.to_data_list():\n",
    "            q_embs.append(data.question_embedding.to(device))\n",
    "            titles_batch.append(data.titles)\n",
    "            supporting_batch.append(data.supporting_titles)\n",
    "        \n",
    "        if q_embs:\n",
    "            q_embs = torch.stack(q_embs)\n",
    "        \n",
    "            # Forward pass\n",
    "            out = gnn_model(batch.x, batch.edge_index)\n",
    "            \n",
    "            batch_loss = 0\n",
    "            \n",
    "            # Process each graph in the batch\n",
    "            for i in range(len(titles_batch)):\n",
    "                # Get passage embeddings for this graph\n",
    "                mask = (batch.batch == i)\n",
    "                passage_embs = out[mask]\n",
    "                \n",
    "                # Get question embedding\n",
    "                q_emb = q_embs[i]\n",
    "                \n",
    "                # Calculate similarity scores\n",
    "                similarities = F.cosine_similarity(\n",
    "                    q_emb.unsqueeze(0).repeat(passage_embs.size(0), 1),\n",
    "                    passage_embs\n",
    "                )\n",
    "                \n",
    "                # Create labels (1 for supporting passages, 0 for others)\n",
    "                labels = torch.zeros(len(titles_batch[i]), device=device)\n",
    "                for idx, title in enumerate(titles_batch[i]):\n",
    "                    if title in supporting_batch[i]:\n",
    "                        labels[idx] = 1.0\n",
    "                \n",
    "                # Find positive and negative indices\n",
    "                pos_indices = torch.where(labels > 0)[0]\n",
    "                neg_indices = torch.where(labels == 0)[0]\n",
    "                \n",
    "                # Compute loss if we have both positive and negative examples\n",
    "                if len(pos_indices) > 0 and len(neg_indices) > 0:\n",
    "                    # Sample a subset of negative examples for efficiency (hard negative mining)\n",
    "                    neg_sims = similarities[neg_indices]\n",
    "                    k = min(5, len(neg_indices))  # At most 5 hard negatives per positive\n",
    "                    hard_neg_indices = neg_indices[torch.topk(neg_sims, k=k).indices]\n",
    "                    \n",
    "                    # Compute pairwise losses\n",
    "                    for pos_idx in pos_indices:\n",
    "                        pos_sim = similarities[pos_idx]\n",
    "                        \n",
    "                        for neg_idx in hard_neg_indices:\n",
    "                            neg_sim = similarities[neg_idx]\n",
    "                            \n",
    "                            # Margin ranking loss\n",
    "                            pair_loss = F.margin_ranking_loss(\n",
    "                                pos_sim.unsqueeze(0),\n",
    "                                neg_sim.unsqueeze(0),\n",
    "                                torch.tensor([1.0], device=device),\n",
    "                                margin=margin\n",
    "                            )\n",
    "                            batch_loss += pair_loss\n",
    "            \n",
    "            # Average loss\n",
    "            if batch_loss > 0:\n",
    "                batch_loss = batch_loss / len(titles_batch)\n",
    "                \n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(gnn_model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += batch_loss.item()\n",
    "                batch_count += 1\n",
    "                \n",
    "            # Force clear CUDA cache periodically\n",
    "            if batch_count % 5 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / batch_count if batch_count > 0 else 0.0\n",
    "\n",
    "def compute_mrr(predictions, ground_truths):\n",
    "    \"\"\"Compute Mean Reciprocal Rank with better error handling\"\"\"\n",
    "    if not predictions or not ground_truths:\n",
    "        print(\"WARNING: Empty predictions or ground truths in MRR computation!\")\n",
    "        return 0.0\n",
    "        \n",
    "    score = 0.0\n",
    "    count = 0\n",
    "    for pred, gt in zip(predictions, ground_truths):\n",
    "        if not gt:  # Skip examples with no ground truth\n",
    "            continue\n",
    "            \n",
    "        for rank, pid in enumerate(pred):\n",
    "            if pid in gt:\n",
    "                score += 1.0 / (rank + 1)\n",
    "                break\n",
    "        count += 1\n",
    "        \n",
    "    return score / count if count > 0 else 0.0\n",
    "\n",
    "def compute_f1_retrieval(predictions, ground_truths, all_keys):\n",
    "    \"\"\"Compute F1 for retrieval with better error handling\"\"\"\n",
    "    if not predictions or not ground_truths or not all_keys:\n",
    "        print(\"WARNING: Empty predictions or ground truths in F1 computation!\")\n",
    "        return 0.0\n",
    "        \n",
    "    total = 0.0\n",
    "    count = 0\n",
    "    for pred, gt, keys in zip(predictions, ground_truths, all_keys):\n",
    "        if not gt:  # Skip examples with no ground truth\n",
    "            continue\n",
    "            \n",
    "        # Create binary vectors for prediction and ground truth\n",
    "        y_true = [1 if key in gt else 0 for key in keys]\n",
    "        y_pred = [1 if key in pred else 0 for key in keys]\n",
    "        \n",
    "        if sum(y_true) > 0:\n",
    "            try:\n",
    "                total += f1_score(y_true, y_pred)\n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error computing F1: {e}\")\n",
    "                continue\n",
    "                \n",
    "    return total / count if count > 0 else 0.0\n",
    "\n",
    "def evaluate_gnn_model(gnn_model, dataset, top_k=5, device=None, batch_size=4, debug=False):\n",
    "    \"\"\"\n",
    "    Fixed evaluation function for GNN model that properly handles global-to-local index mapping\n",
    "    \n",
    "    Args:\n",
    "        gnn_model: GNN model\n",
    "        dataset: Dataset for evaluation\n",
    "        top_k: Number of top passages to retrieve\n",
    "        device: Device to use\n",
    "        batch_size: Batch size for evaluation\n",
    "        debug: Whether to print debug information\n",
    "        \n",
    "    Returns:\n",
    "        MRR and F1 scores\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    gnn_model.eval()\n",
    "    \n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    all_titles = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(loader, desc=\"Evaluating\")):\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            # Process each graph in batch individually to avoid index mapping issues\n",
    "            for i, data in enumerate(batch.to_data_list()):\n",
    "                # Move individual data to device\n",
    "                data_x = data.x.to(device)\n",
    "                data_edge_index = data.edge_index.to(device)\n",
    "                q_emb = data.question_embedding.to(device)\n",
    "                \n",
    "                # Forward pass with this single graph\n",
    "                node_embs = gnn_model(data_x, data_edge_index)\n",
    "                \n",
    "                # Calculate similarity\n",
    "                similarities = F.cosine_similarity(\n",
    "                    q_emb.unsqueeze(0).repeat(len(data.titles), 1),\n",
    "                    node_embs\n",
    "                )\n",
    "                \n",
    "                # Get top-k predictions\n",
    "                top_indices = torch.topk(similarities, k=min(top_k, len(data.titles))).indices.tolist()\n",
    "                pred_titles = [data.titles[idx] for idx in top_indices]\n",
    "                \n",
    "                # Store results\n",
    "                predictions.append(pred_titles)\n",
    "                ground_truths.append(data.supporting_titles)\n",
    "                all_titles.append(data.titles)\n",
    "                \n",
    "                # Print debug info for first few examples\n",
    "                if debug and len(predictions) <= 3:\n",
    "                    print(f\"\\nExample {len(predictions)}:\")\n",
    "                    print(f\"  Question: [Hidden for brevity]\")\n",
    "                    print(f\"  Predictions: {pred_titles}\")\n",
    "                    print(f\"  Ground truth: {data.supporting_titles}\")\n",
    "                    print(f\"  Overlap: {set(pred_titles) & set(data.supporting_titles)}\")\n",
    "            \n",
    "            # Clear cache\n",
    "            if batch_idx % 5 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    # Print some statistics for debugging\n",
    "    if debug:\n",
    "        print(f\"\\nEvaluation statistics:\")\n",
    "        print(f\"  Total examples evaluated: {len(predictions)}\")\n",
    "        overlap_count = sum(1 for pred, gt in zip(predictions, ground_truths) \n",
    "                           if len(set(pred) & set(gt)) > 0)\n",
    "        print(f\"  Examples with at least one correct prediction: {overlap_count}\")\n",
    "        print(f\"  Percentage with correct predictions: {overlap_count/len(predictions)*100:.2f}%\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mrr = compute_mrr(predictions, ground_truths)\n",
    "    f1 = compute_f1_retrieval(predictions, ground_truths, all_titles)\n",
    "    \n",
    "    return mrr, f1\n",
    "\n",
    "# --- Compare Different Aggregation Functions ---\n",
    "def compare_aggregation_functions(train_dataset, val_dataset, in_channels=384, \n",
    "                                  hidden_channels=128, out_channels=384, \n",
    "                                  batch_size=4, num_epochs=2, device=None):\n",
    "    \"\"\"\n",
    "    Compare performance of different aggregation functions\n",
    "    \n",
    "    Args:\n",
    "        train_dataset: PyG dataset for training\n",
    "        val_dataset: PyG dataset for validation\n",
    "        in_channels: Input dimension\n",
    "        hidden_channels: Hidden layer dimension\n",
    "        out_channels: Output dimension\n",
    "        batch_size: Batch size for training\n",
    "        num_epochs: Number of training epochs\n",
    "        device: Device to use\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of results for each aggregation function\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Create data loaders with smaller batch sizes\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Aggregation functions to try\n",
    "    aggregations = ['mean', 'max', 'sum', 'min']\n",
    "    \n",
    "    # Store results\n",
    "    results = {}\n",
    "    \n",
    "    for aggr in aggregations:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training with {aggr.upper()} aggregation\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = ImprovedPassageGNN(\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            out_channels=out_channels,\n",
    "            num_layers=3,  # Increased from 2 to 3 layers\n",
    "            dropout=0.3,\n",
    "            aggregation=aggr\n",
    "        ).to(device)\n",
    "        \n",
    "        # Optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "        \n",
    "        # Training history\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'val_mrr': [],\n",
    "            'val_f1': []\n",
    "        }\n",
    "        \n",
    "        # Train for specified epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            # Train with memory-efficient function\n",
    "            train_loss = train_gnn_batch(train_loader, model, optimizer, device=device)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}\")\n",
    "            history['train_loss'].append(train_loss)\n",
    "            \n",
    "            # Evaluate\n",
    "            val_mrr, val_f1 = evaluate_gnn_model(model, val_dataset, device=device)\n",
    "            print(f\"Validation - MRR: {val_mrr:.4f}, F1: {val_f1:.4f}\")\n",
    "            history['val_mrr'].append(val_mrr)\n",
    "            history['val_f1'].append(val_f1)\n",
    "            \n",
    "            # Save GPU memory\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Store results for this aggregation\n",
    "        results[aggr] = {\n",
    "            'model': model,\n",
    "            'history': history,\n",
    "            'final_mrr': val_mrr,\n",
    "            'final_f1': val_f1\n",
    "        }\n",
    "        \n",
    "        # Save model to disk\n",
    "        torch.save(model.state_dict(), f'gnn_model_{aggr}_improved.pt')\n",
    "        \n",
    "    return results\n",
    "\n",
    "def visualize_aggregation_results(results):\n",
    "    \"\"\"\n",
    "    Visualize comparison of different aggregation functions\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary of results from compare_aggregation_functions\n",
    "    \"\"\"\n",
    "    aggregations = list(results.keys())\n",
    "    mrr_values = [results[aggr]['final_mrr'] for aggr in aggregations]\n",
    "    f1_values = [results[aggr]['final_f1'] for aggr in aggregations]\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot training loss curves\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for aggr in aggregations:\n",
    "        plt.plot(results[aggr]['history']['train_loss'], label=aggr.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title('Training Loss by Aggregation Function')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot validation MRR curves\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for aggr in aggregations:\n",
    "        plt.plot(results[aggr]['history']['val_mrr'], label=aggr.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation MRR')\n",
    "    plt.title('Validation MRR by Aggregation Function')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # MRR comparison bar chart\n",
    "    plt.subplot(2, 2, 3)\n",
    "    x = np.arange(len(aggregations))\n",
    "    plt.bar(x, mrr_values, width=0.6, color='skyblue')\n",
    "    plt.xlabel('Aggregation Function')\n",
    "    plt.ylabel('MRR')\n",
    "    plt.title('Final MRR by Aggregation Function')\n",
    "    plt.xticks(x, [aggr.upper() for aggr in aggregations])\n",
    "    plt.ylim(0, max(mrr_values) * 1.2)\n",
    "    plt.grid(True, axis='y')\n",
    "    \n",
    "    # F1 comparison bar chart\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.bar(x, f1_values, width=0.6, color='lightgreen')\n",
    "    plt.xlabel('Aggregation Function')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('Final F1 Score by Aggregation Function')\n",
    "    plt.xticks(x, [aggr.upper() for aggr in aggregations])\n",
    "    plt.ylim(0, max(f1_values) * 1.2)\n",
    "    plt.grid(True, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('aggregation_comparison_improved.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\nAggregation Function Comparison:\")\n",
    "    print(\"================================\")\n",
    "    print(f\"{'Aggregation':<12} {'MRR':<10} {'F1':<10}\")\n",
    "    print(\"-\" * 32)\n",
    "    for aggr in aggregations:\n",
    "        print(f\"{aggr.upper():<12} {results[aggr]['final_mrr']:.4f}     {results[aggr]['final_f1']:.4f}\")\n",
    "    \n",
    "    # Identify best function\n",
    "    best_mrr_idx = np.argmax(mrr_values)\n",
    "    best_f1_idx = np.argmax(f1_values)\n",
    "    \n",
    "    print(\"\\nBest for MRR: \" + aggregations[best_mrr_idx].upper())\n",
    "    print(\"Best for F1: \" + aggregations[best_f1_idx].upper())\n",
    "\n",
    "# --- Baseline Evaluation Functions ---\n",
    "def evaluate_bm25(df, num_samples=300, k=5):\n",
    "    \"\"\"Evaluate BM25 baseline\"\"\"\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    \n",
    "    # Lists to store results\n",
    "    preds = []\n",
    "    gts = []\n",
    "    titles_list = []\n",
    "    \n",
    "    for i, row in tqdm(df.iloc[:num_samples].iterrows(), total=min(num_samples, len(df)), desc=\"Evaluating BM25\"):\n",
    "        question = row['question']\n",
    "        context = [tuple(x) for x in row['context']]\n",
    "        titles = [title for title, _ in context]\n",
    "        texts = [\" \".join(text) if isinstance(text, list) else text for _, text in context]\n",
    "        supporting_titles = [x[0] for x in row['supporting_facts']]\n",
    "        \n",
    "        # Skip if empty\n",
    "        if not titles or not texts:\n",
    "            continue\n",
    "            \n",
    "        # Tokenize\n",
    "        tokenized_corpus = [doc.lower().split() for doc in texts]\n",
    "        tokenized_query = question.lower().split()\n",
    "        \n",
    "        # BM25 ranking\n",
    "        try:\n",
    "            bm25 = BM25Okapi(tokenized_corpus)\n",
    "            doc_scores = bm25.get_scores(tokenized_query)\n",
    "            \n",
    "            # Get top k\n",
    "            top_indices = np.argsort(doc_scores)[::-1][:k]\n",
    "            retrieved_titles = [titles[idx] for idx in top_indices]\n",
    "            \n",
    "            preds.append(retrieved_titles)\n",
    "            gts.append(supporting_titles)\n",
    "            titles_list.append(titles)\n",
    "        except Exception as e:\n",
    "            print(f\"BM25 error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate metrics with special handling for empty predictions or ground truths\n",
    "    mrr = compute_mrr(preds, gts)\n",
    "    f1 = compute_f1_retrieval(preds, gts, titles_list)\n",
    "    \n",
    "    print(f\"BM25 Results (k={k}):\")\n",
    "    print(f\"  MRR: {mrr:.4f}\")\n",
    "    print(f\"  F1: {f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"mrr\": mrr,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "def evaluate_dense_retrieval(df, model_name='all-MiniLM-L6-v2', num_samples=300, k=5):\n",
    "    \"\"\"Evaluate Dense Passage Retrieval baseline\"\"\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Lists to store results\n",
    "    preds = []\n",
    "    gts = []\n",
    "    titles_list = []\n",
    "    \n",
    "    for i, row in tqdm(df.iloc[:num_samples].iterrows(), total=min(num_samples, len(df)), desc=\"Evaluating DPR\"):\n",
    "        question = row['question']\n",
    "        context = [tuple(x) for x in row['context']]\n",
    "        titles = [title for title, _ in context]\n",
    "        texts = [\" \".join(text) if isinstance(text, list) else text for _, text in context]\n",
    "        supporting_titles = [x[0] for x in row['supporting_facts']]\n",
    "        \n",
    "        # Skip if empty\n",
    "        if not titles or not texts:\n",
    "            continue\n",
    "            \n",
    "        # Process in batches to save memory\n",
    "        batch_size = 16\n",
    "        all_passage_embs = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            batch_embs = model.encode(batch_texts, convert_to_tensor=True, device=preprocess_device)\n",
    "            all_passage_embs.append(batch_embs)\n",
    "            \n",
    "        # Concatenate all embeddings\n",
    "        p_embs = torch.cat(all_passage_embs, dim=0)\n",
    "        \n",
    "        # Encode question\n",
    "        q_emb = model.encode(question, convert_to_tensor=True, device=preprocess_device)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = util.pytorch_cos_sim(q_emb, p_embs)[0].cpu().numpy()\n",
    "        \n",
    "        # Get top k\n",
    "        top_indices = np.argsort(similarities)[::-1][:k]\n",
    "        retrieved_titles = [titles[idx] for idx in top_indices]\n",
    "        \n",
    "        preds.append(retrieved_titles)\n",
    "        gts.append(supporting_titles)\n",
    "        titles_list.append(titles)\n",
    "        \n",
    "        # Clear memory\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mrr = compute_mrr(preds, gts)\n",
    "    f1 = compute_f1_retrieval(preds, gts, titles_list)\n",
    "    \n",
    "    print(f\"Dense Retrieval Results (k={k}):\")\n",
    "    print(f\"  MRR: {mrr:.4f}\")\n",
    "    print(f\"  F1: {f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"mrr\": mrr,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "# Create the cached embedder\n",
    "embedder = CachedEmbedder(\"all-MiniLM-L6-v2\", device=preprocess_device)\n",
    "\n",
    "# Set sample sizes for larger dataset (as requested)\n",
    "train_sample_size = 1000   # Increased from original\n",
    "val_sample_size = 300\n",
    "test_sample_size = 300\n",
    "\n",
    "# Build datasets with chunking for memory efficiency\n",
    "train_dataset = build_dataset(\n",
    "    train_df, \n",
    "    embedder, \n",
    "    max_samples=train_sample_size,\n",
    "    save_path=\"train_dataset_large.pkl\",\n",
    "    chunk_size=50  # Process in chunks of 50\n",
    ")\n",
    "\n",
    "val_dataset = build_dataset(\n",
    "    val_df, \n",
    "    embedder, \n",
    "    max_samples=val_sample_size,\n",
    "    save_path=\"val_dataset_large.pkl\",\n",
    "    chunk_size=50\n",
    ")\n",
    "\n",
    "test_dataset = build_dataset(\n",
    "    test_df, \n",
    "    embedder, \n",
    "    max_samples=test_sample_size,\n",
    "    save_path=\"test_dataset_large.pkl\",\n",
    "    chunk_size=50\n",
    ")\n",
    "\n",
    "# Display dataset sizes\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"Train: {len(train_dataset)} examples\")\n",
    "print(f\"Validation: {len(val_dataset)} examples\")\n",
    "print(f\"Test: {len(test_dataset)} examples\")\n",
    "\n",
    "# Compare different aggregation functions with increased epochs\n",
    "results = compare_aggregation_functions(\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    in_channels=384,  # Dimension for all-MiniLM-L6-v2\n",
    "    hidden_channels=128,\n",
    "    out_channels=384,\n",
    "    batch_size=8,     # Adjusted batch size for memory efficiency\n",
    "    num_epochs=5,     # Increased from 2 to 5 epochs\n",
    "    device=main_device\n",
    ")\n",
    "\n",
    "# Visualize and analyze results\n",
    "visualize_aggregation_results(results)\n",
    "\n",
    "# Get best model based on validation MRR\n",
    "best_aggr = max(results.keys(), key=lambda k: results[k]['final_mrr'])\n",
    "print(f\"Best aggregation function by MRR: {best_aggr.upper()}\")\n",
    "\n",
    "# Load the best model for final evaluation\n",
    "best_model = ImprovedPassageGNN(\n",
    "    in_channels=384,\n",
    "    hidden_channels=128,\n",
    "    out_channels=384,\n",
    "    num_layers=3,  # Increased from 2\n",
    "    dropout=0.3,\n",
    "    aggregation=best_aggr\n",
    ").to(main_device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(f'gnn_model_{best_aggr}_improved.pt', map_location=main_device))\n",
    "best_model.eval()\n",
    "\n",
    "# Evaluate on test set with enhanced debugging (fixed version)\n",
    "test_mrr, test_f1 = evaluate_gnn_model(best_model, test_dataset, device=main_device, debug=True)\n",
    "print(f\"\\n=== Final Test Results with {best_aggr.upper()} Aggregation ===\")\n",
    "print(f\"Test MRR: {test_mrr:.4f}\")\n",
    "print(f\"Test F1: {test_f1:.4f}\")\n",
    "\n",
    "# Run baseline evaluations for comparison\n",
    "print(\"\\nRunning baseline evaluations...\")\n",
    "bm25_results = evaluate_bm25(test_df, num_samples=test_sample_size)\n",
    "dpr_results = evaluate_dense_retrieval(test_df, num_samples=test_sample_size)\n",
    "\n",
    "# Create comparison table\n",
    "gnn_results = {\"mrr\": test_mrr, \"f1\": test_f1}\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['BM25', 'Dense Retrieval', f'GNN ({best_aggr.upper()})'],\n",
    "    'MRR': [bm25_results['mrr'], dpr_results['mrr'], gnn_results['mrr']],\n",
    "    'F1': [bm25_results['f1'], dpr_results['f1'], gnn_results['f1']]\n",
    "})\n",
    "\n",
    "print(\"\\nRetrieval Model Comparison:\")\n",
    "print(comparison)\n",
    "\n",
    "# Save results\n",
    "comparison.to_csv(\"model_comparison_results.csv\")\n",
    "print(\"Results saved to model_comparison_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2a052be-ee94-42b4-9f0f-167ef2a50665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training example structure:\n",
      "[['Move (1970 film)', 0], ['Méditerranée (1963 film)', 0], ['Stuart Rosenberg', 0], ['Jean-Daniel Pollet', 0]]\n",
      "\n",
      "Validation example structure:\n",
      "[['Polish-Russian War (film)', 1], ['Xawery Żuławski', 2]]\n",
      "\n",
      "Test example structure:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Check structure of first few examples in each dataset\n",
    "print(\"\\nTraining example structure:\")\n",
    "print(train_df.iloc[0]['supporting_facts'])\n",
    "\n",
    "print(\"\\nValidation example structure:\")\n",
    "print(val_df.iloc[0]['supporting_facts'])\n",
    "\n",
    "print(\"\\nTest example structure:\")\n",
    "print(test_df.iloc[0]['supporting_facts'])  # Is this empty or different?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5b16e-5d4d-4334-a3a5-5bec12d1e7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4cd3e-54ed-4279-a1eb-7159b6253ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f54e44b5-f164-47b2-9494-fae691c0c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main device: cuda\n",
      "Preprocessing device: cuda\n",
      "Loading data...\n",
      "Train samples: 167454, Val samples: 12576, Test samples: 12576\n",
      "Building train dataset (1500 examples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43843009b4b24ea9afabdb05021153f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building train dataset:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing example 1: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 52: expected Tensor as element 6 in argument 0, but got float\n",
      "Error processing example 69: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 105: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 120: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 125: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 143: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 166: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 169: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 181: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 187: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 192: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 206: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 226: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 227: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 243: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 244: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 265: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 266: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 281: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 347: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 363: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 381: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 385: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 393: expected Tensor as element 5 in argument 0, but got float\n",
      "Error processing example 432: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 455: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 457: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 462: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 467: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 475: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 499: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 500: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 503: expected Tensor as element 8 in argument 0, but got float\n",
      "Error processing example 541: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 580: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 595: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 606: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 607: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 609: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 645: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 663: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 670: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 696: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 727: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 729: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 743: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 745: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 780: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 782: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 785: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 808: expected Tensor as element 6 in argument 0, but got float\n",
      "Error processing example 831: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 832: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 851: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 866: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 880: expected Tensor as element 8 in argument 0, but got float\n",
      "Error processing example 898: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 954: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 955: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 973: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 974: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 985: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 1015: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 1025: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1029: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 1061: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1066: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 1073: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1103: expected Tensor as element 3 in argument 0, but got numpy.float64\n",
      "Error processing example 1123: expected Tensor as element 6 in argument 0, but got float\n",
      "Error processing example 1144: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 1160: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 1173: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 1193: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1196: expected Tensor as element 8 in argument 0, but got float\n",
      "Error processing example 1200: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1218: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1234: expected Tensor as element 5 in argument 0, but got float\n",
      "Error processing example 1285: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1293: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1303: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1307: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1312: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1323: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 1330: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1341: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1350: expected Tensor as element 3 in argument 0, but got numpy.float64\n",
      "Error processing example 1356: expected Tensor as element 6 in argument 0, but got float\n",
      "Error processing example 1366: expected Tensor as element 6 in argument 0, but got float\n",
      "Error processing example 1392: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 1400: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1407: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 1428: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1434: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1447: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 1449: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1456: expected Tensor as element 3 in argument 0, but got numpy.float64\n",
      "Error processing example 1464: expected Tensor as element 5 in argument 0, but got float\n",
      "Error processing example 1484: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 1489: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Saved dataset to train_dataset.pkl\n",
      "Built train dataset with 1399 examples\n",
      "Building dev dataset (300 examples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e6f008b6a64474b2fe9ee79e392274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building dev dataset:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing example 2: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 5: expected Tensor as element 4 in argument 0, but got numpy.float64\n",
      "Error processing example 29: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 34: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 41: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 43: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 47: expected Tensor as element 6 in argument 0, but got float\n",
      "Error processing example 54: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 67: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 73: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 78: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 89: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 93: expected Tensor as element 3 in argument 0, but got numpy.float64\n",
      "Error processing example 99: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 111: expected Tensor as element 5 in argument 0, but got float\n",
      "Error processing example 116: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 122: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 125: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 131: expected Tensor as element 6 in argument 0, but got float\n",
      "Error processing example 132: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 137: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 142: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 147: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 160: expected Tensor as element 8 in argument 0, but got numpy.float64\n",
      "Error processing example 170: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 174: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 175: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 178: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 194: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 197: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 211: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 212: expected Tensor as element 6 in argument 0, but got float\n",
      "Error processing example 221: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 235: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 239: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 244: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 251: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 258: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 263: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 267: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 273: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 275: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 295: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 296: expected Tensor as element 2 in argument 0, but got numpy.float64\n",
      "Error processing example 297: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Error processing example 298: expected Tensor as element 8 in argument 0, but got float\n",
      "Saved dataset to dev_dataset.pkl\n",
      "Built dev dataset with 254 examples\n",
      "Tuning with margin=0.05, sim_scale=10.0\n",
      "Epoch 1/10 Loss: 0.1378, Eval F1: 0.5010, Eval MRR: 0.8062\n",
      "Epoch 2/10 Loss: 0.0629, Eval F1: 0.4958, Eval MRR: 0.8012\n",
      "Epoch 3/10 Loss: 0.0555, Eval F1: 0.5046, Eval MRR: 0.8106\n",
      "Epoch 4/10 Loss: 0.0527, Eval F1: 0.5082, Eval MRR: 0.8017\n",
      "Epoch 5/10 Loss: 0.0528, Eval F1: 0.5127, Eval MRR: 0.7912\n",
      "Epoch 6/10 Loss: 0.0503, Eval F1: 0.4918, Eval MRR: 0.7372\n",
      "Epoch 7/10 Loss: 0.0364, Eval F1: 0.4842, Eval MRR: 0.6904\n",
      "Epoch 8/10 Loss: 0.0268, Eval F1: 0.4988, Eval MRR: 0.7264\n",
      "Epoch 9/10 Loss: 0.0229, Eval F1: 0.5310, Eval MRR: 0.7399\n",
      "Epoch 10/10 Loss: 0.0201, Eval F1: 0.5365, Eval MRR: 0.7501\n",
      "Config margin=0.05, sim_scale=10.0: Eval F1: 0.5365, Eval MRR: 0.7501\n",
      "\n",
      "Tuning with margin=0.05, sim_scale=20.0\n",
      "Epoch 1/10 Loss: 0.2437, Eval F1: 0.4906, Eval MRR: 0.7615\n",
      "Epoch 2/10 Loss: 0.0915, Eval F1: 0.4986, Eval MRR: 0.7797\n",
      "Epoch 3/10 Loss: 0.0693, Eval F1: 0.5068, Eval MRR: 0.7774\n",
      "Epoch 4/10 Loss: 0.0630, Eval F1: 0.5033, Eval MRR: 0.7662\n",
      "Epoch 5/10 Loss: 0.0587, Eval F1: 0.5002, Eval MRR: 0.7602\n",
      "Epoch 6/10 Loss: 0.0532, Eval F1: 0.4668, Eval MRR: 0.6924\n",
      "Epoch 7/10 Loss: 0.0381, Eval F1: 0.4692, Eval MRR: 0.6977\n",
      "Epoch 8/10 Loss: 0.0308, Eval F1: 0.4853, Eval MRR: 0.7172\n",
      "Epoch 9/10 Loss: 0.0283, Eval F1: 0.5051, Eval MRR: 0.7283\n",
      "Epoch 10/10 Loss: 0.0252, Eval F1: 0.5167, Eval MRR: 0.7379\n",
      "Config margin=0.05, sim_scale=20.0: Eval F1: 0.5167, Eval MRR: 0.7379\n",
      "\n",
      "Tuning with margin=0.05, sim_scale=30.0\n",
      "Epoch 1/10 Loss: 0.3417, Eval F1: 0.4968, Eval MRR: 0.7786\n",
      "Epoch 2/10 Loss: 0.1166, Eval F1: 0.5015, Eval MRR: 0.7705\n",
      "Epoch 3/10 Loss: 0.0890, Eval F1: 0.5032, Eval MRR: 0.7528\n",
      "Epoch 4/10 Loss: 0.0783, Eval F1: 0.4992, Eval MRR: 0.7639\n",
      "Epoch 5/10 Loss: 0.0703, Eval F1: 0.5031, Eval MRR: 0.7723\n",
      "Epoch 6/10 Loss: 0.0641, Eval F1: 0.4906, Eval MRR: 0.7671\n",
      "Epoch 7/10 Loss: 0.0581, Eval F1: 0.4740, Eval MRR: 0.7029\n",
      "Epoch 8/10 Loss: 0.0439, Eval F1: 0.4737, Eval MRR: 0.7052\n",
      "Epoch 9/10 Loss: 0.0351, Eval F1: 0.4978, Eval MRR: 0.7215\n",
      "Epoch 10/10 Loss: 0.0305, Eval F1: 0.5110, Eval MRR: 0.7164\n",
      "Config margin=0.05, sim_scale=30.0: Eval F1: 0.5110, Eval MRR: 0.7164\n",
      "\n",
      "Tuning with margin=0.1, sim_scale=10.0\n",
      "Epoch 1/10 Loss: 0.1639, Eval F1: 0.4947, Eval MRR: 0.8068\n",
      "Epoch 2/10 Loss: 0.1057, Eval F1: 0.4987, Eval MRR: 0.8106\n",
      "Epoch 3/10 Loss: 0.1031, Eval F1: 0.5147, Eval MRR: 0.7850\n",
      "Epoch 4/10 Loss: 0.0998, Eval F1: 0.5106, Eval MRR: 0.8051\n",
      "Epoch 5/10 Loss: 0.0902, Eval F1: 0.4756, Eval MRR: 0.6956\n",
      "Epoch 6/10 Loss: 0.0595, Eval F1: 0.4938, Eval MRR: 0.7131\n",
      "Epoch 7/10 Loss: 0.0459, Eval F1: 0.5208, Eval MRR: 0.7340\n",
      "Epoch 8/10 Loss: 0.0394, Eval F1: 0.5322, Eval MRR: 0.7377\n",
      "Epoch 9/10 Loss: 0.0348, Eval F1: 0.5352, Eval MRR: 0.7750\n",
      "Epoch 10/10 Loss: 0.0295, Eval F1: 0.5569, Eval MRR: 0.7912\n",
      "Config margin=0.1, sim_scale=10.0: Eval F1: 0.5569, Eval MRR: 0.7912\n",
      "\n",
      "Tuning with margin=0.1, sim_scale=20.0\n",
      "Epoch 1/10 Loss: 0.2612, Eval F1: 0.4784, Eval MRR: 0.7573\n",
      "Epoch 2/10 Loss: 0.1234, Eval F1: 0.4822, Eval MRR: 0.7533\n",
      "Epoch 3/10 Loss: 0.1090, Eval F1: 0.4739, Eval MRR: 0.7476\n",
      "Epoch 4/10 Loss: 0.1061, Eval F1: 0.4808, Eval MRR: 0.7448\n",
      "Epoch 5/10 Loss: 0.0912, Eval F1: 0.4746, Eval MRR: 0.6835\n",
      "Epoch 6/10 Loss: 0.0643, Eval F1: 0.4943, Eval MRR: 0.7000\n",
      "Epoch 7/10 Loss: 0.0527, Eval F1: 0.5099, Eval MRR: 0.7305\n",
      "Epoch 8/10 Loss: 0.0436, Eval F1: 0.5248, Eval MRR: 0.7417\n",
      "Epoch 9/10 Loss: 0.0374, Eval F1: 0.5434, Eval MRR: 0.7842\n",
      "Epoch 10/10 Loss: 0.0349, Eval F1: 0.5507, Eval MRR: 0.7853\n",
      "Config margin=0.1, sim_scale=20.0: Eval F1: 0.5507, Eval MRR: 0.7853\n",
      "\n",
      "Tuning with margin=0.1, sim_scale=30.0\n",
      "Epoch 1/10 Loss: 0.3705, Eval F1: 0.5062, Eval MRR: 0.7839\n",
      "Epoch 2/10 Loss: 0.1527, Eval F1: 0.5093, Eval MRR: 0.7780\n",
      "Epoch 3/10 Loss: 0.1246, Eval F1: 0.5056, Eval MRR: 0.7653\n",
      "Epoch 4/10 Loss: 0.1122, Eval F1: 0.4794, Eval MRR: 0.7171\n",
      "Epoch 5/10 Loss: 0.0865, Eval F1: 0.4913, Eval MRR: 0.7129\n",
      "Epoch 6/10 Loss: 0.0664, Eval F1: 0.4891, Eval MRR: 0.6878\n",
      "Epoch 7/10 Loss: 0.0547, Eval F1: 0.5011, Eval MRR: 0.7004\n",
      "Epoch 8/10 Loss: 0.0488, Eval F1: 0.5223, Eval MRR: 0.7340\n",
      "Epoch 9/10 Loss: 0.0426, Eval F1: 0.5292, Eval MRR: 0.7513\n",
      "Epoch 10/10 Loss: 0.0385, Eval F1: 0.5377, Eval MRR: 0.7740\n",
      "Config margin=0.1, sim_scale=30.0: Eval F1: 0.5377, Eval MRR: 0.7740\n",
      "\n",
      "Tuning with margin=0.2, sim_scale=10.0\n",
      "Epoch 1/10 Loss: 0.2504, Eval F1: 0.5104, Eval MRR: 0.8016\n",
      "Epoch 2/10 Loss: 0.2014, Eval F1: 0.5027, Eval MRR: 0.8054\n",
      "Epoch 3/10 Loss: 0.1509, Eval F1: 0.4859, Eval MRR: 0.7070\n",
      "Epoch 4/10 Loss: 0.1009, Eval F1: 0.5107, Eval MRR: 0.7170\n",
      "Epoch 5/10 Loss: 0.0829, Eval F1: 0.5329, Eval MRR: 0.7599\n",
      "Epoch 6/10 Loss: 0.0696, Eval F1: 0.5529, Eval MRR: 0.7661\n",
      "Epoch 7/10 Loss: 0.0592, Eval F1: 0.5612, Eval MRR: 0.7783\n",
      "Epoch 8/10 Loss: 0.0500, Eval F1: 0.5640, Eval MRR: 0.8016\n",
      "Epoch 9/10 Loss: 0.0420, Eval F1: 0.5748, Eval MRR: 0.8215\n",
      "Epoch 10/10 Loss: 0.0354, Eval F1: 0.5729, Eval MRR: 0.8321\n",
      "Config margin=0.2, sim_scale=10.0: Eval F1: 0.5729, Eval MRR: 0.8321\n",
      "\n",
      "Tuning with margin=0.2, sim_scale=20.0\n",
      "Epoch 1/10 Loss: 0.3448, Eval F1: 0.5044, Eval MRR: 0.7951\n",
      "Epoch 2/10 Loss: 0.2094, Eval F1: 0.5072, Eval MRR: 0.8036\n",
      "Epoch 3/10 Loss: 0.1990, Eval F1: 0.5102, Eval MRR: 0.7924\n",
      "Epoch 4/10 Loss: 0.1667, Eval F1: 0.4808, Eval MRR: 0.7005\n",
      "Epoch 5/10 Loss: 0.1179, Eval F1: 0.4804, Eval MRR: 0.7140\n",
      "Epoch 6/10 Loss: 0.1015, Eval F1: 0.5013, Eval MRR: 0.7192\n",
      "Epoch 7/10 Loss: 0.0901, Eval F1: 0.5091, Eval MRR: 0.7492\n",
      "Epoch 8/10 Loss: 0.0819, Eval F1: 0.5297, Eval MRR: 0.7854\n",
      "Epoch 9/10 Loss: 0.0706, Eval F1: 0.5422, Eval MRR: 0.7983\n",
      "Epoch 10/10 Loss: 0.0562, Eval F1: 0.5584, Eval MRR: 0.8126\n",
      "Config margin=0.2, sim_scale=20.0: Eval F1: 0.5584, Eval MRR: 0.8126\n",
      "\n",
      "Tuning with margin=0.2, sim_scale=30.0\n",
      "Epoch 1/10 Loss: 0.4500, Eval F1: 0.4956, Eval MRR: 0.7776\n",
      "Epoch 2/10 Loss: 0.2292, Eval F1: 0.5032, Eval MRR: 0.7730\n",
      "Epoch 3/10 Loss: 0.2083, Eval F1: 0.4907, Eval MRR: 0.7672\n",
      "Epoch 4/10 Loss: 0.1631, Eval F1: 0.4857, Eval MRR: 0.7016\n",
      "Epoch 5/10 Loss: 0.1204, Eval F1: 0.5022, Eval MRR: 0.7047\n",
      "Epoch 6/10 Loss: 0.0987, Eval F1: 0.5173, Eval MRR: 0.7451\n",
      "Epoch 7/10 Loss: 0.0841, Eval F1: 0.5283, Eval MRR: 0.7497\n",
      "Epoch 8/10 Loss: 0.0747, Eval F1: 0.5444, Eval MRR: 0.7766\n",
      "Epoch 9/10 Loss: 0.0644, Eval F1: 0.5599, Eval MRR: 0.7907\n",
      "Epoch 10/10 Loss: 0.0575, Eval F1: 0.5668, Eval MRR: 0.8055\n",
      "Config margin=0.2, sim_scale=30.0: Eval F1: 0.5668, Eval MRR: 0.8055\n",
      "\n",
      "Tuning results:\n",
      "Margin: 0.05, SIM_SCALE: 10.0 -> F1: 0.5365, MRR: 0.7501\n",
      "Margin: 0.05, SIM_SCALE: 20.0 -> F1: 0.5167, MRR: 0.7379\n",
      "Margin: 0.05, SIM_SCALE: 30.0 -> F1: 0.5110, MRR: 0.7164\n",
      "Margin: 0.1, SIM_SCALE: 10.0 -> F1: 0.5569, MRR: 0.7912\n",
      "Margin: 0.1, SIM_SCALE: 20.0 -> F1: 0.5507, MRR: 0.7853\n",
      "Margin: 0.1, SIM_SCALE: 30.0 -> F1: 0.5377, MRR: 0.7740\n",
      "Margin: 0.2, SIM_SCALE: 10.0 -> F1: 0.5729, MRR: 0.8321\n",
      "Margin: 0.2, SIM_SCALE: 20.0 -> F1: 0.5584, MRR: 0.8126\n",
      "Margin: 0.2, SIM_SCALE: 30.0 -> F1: 0.5668, MRR: 0.8055\n",
      "Best configuration: {'margin': 0.2, 'sim_scale': 10.0} with F1: 0.5729\n",
      "Starting final training with best hyperparameters...\n",
      "Epoch 1/50 Loss: 0.2419, Eval F1: 0.5056, Eval MRR: 0.7765\n",
      "Epoch 2/50 Loss: 0.1896, Eval F1: 0.4734, Eval MRR: 0.7037\n",
      "Epoch 3/50 Loss: 0.1263, Eval F1: 0.4738, Eval MRR: 0.6848\n",
      "Epoch 4/50 Loss: 0.0952, Eval F1: 0.5054, Eval MRR: 0.7542\n",
      "Epoch 5/50 Loss: 0.0780, Eval F1: 0.5425, Eval MRR: 0.7755\n",
      "Epoch 6/50 Loss: 0.0655, Eval F1: 0.5599, Eval MRR: 0.8097\n",
      "Epoch 7/50 Loss: 0.0546, Eval F1: 0.5549, Eval MRR: 0.8193\n",
      "Epoch 8/50 Loss: 0.0504, Eval F1: 0.5652, Eval MRR: 0.8112\n",
      "Epoch 9/50 Loss: 0.0416, Eval F1: 0.5640, Eval MRR: 0.8226\n",
      "Epoch 10/50 Loss: 0.0358, Eval F1: 0.5682, Eval MRR: 0.8252\n",
      "Epoch 11/50 Loss: 0.0295, Eval F1: 0.5807, Eval MRR: 0.8493\n",
      "Epoch 12/50 Loss: 0.0272, Eval F1: 0.5822, Eval MRR: 0.8354\n",
      "Epoch 13/50 Loss: 0.0247, Eval F1: 0.5905, Eval MRR: 0.8516\n",
      "Epoch 14/50 Loss: 0.0225, Eval F1: 0.5769, Eval MRR: 0.8399\n",
      "Epoch 15/50 Loss: 0.0188, Eval F1: 0.5772, Eval MRR: 0.8563\n",
      "Epoch 16/50 Loss: 0.0168, Eval F1: 0.5762, Eval MRR: 0.8612\n",
      "Epoch 17/50 Loss: 0.0153, Eval F1: 0.5775, Eval MRR: 0.8652\n",
      "Epoch 18/50 Loss: 0.0151, Eval F1: 0.5793, Eval MRR: 0.8434\n",
      "Epoch 19/50 Loss: 0.0132, Eval F1: 0.5789, Eval MRR: 0.8542\n",
      "Epoch 20/50 Loss: 0.0121, Eval F1: 0.5903, Eval MRR: 0.8605\n",
      "Epoch 21/50 Loss: 0.0096, Eval F1: 0.5904, Eval MRR: 0.8569\n",
      "Epoch 22/50 Loss: 0.0096, Eval F1: 0.5819, Eval MRR: 0.8730\n",
      "Epoch 23/50 Loss: 0.0091, Eval F1: 0.5862, Eval MRR: 0.8617\n",
      "Epoch 24/50 Loss: 0.0082, Eval F1: 0.5828, Eval MRR: 0.8601\n",
      "Epoch 25/50 Loss: 0.0092, Eval F1: 0.5797, Eval MRR: 0.8319\n",
      "Epoch 26/50 Loss: 0.0089, Eval F1: 0.5759, Eval MRR: 0.8545\n",
      "Epoch 27/50 Loss: 0.0058, Eval F1: 0.5815, Eval MRR: 0.8650\n",
      "Epoch 28/50 Loss: 0.0057, Eval F1: 0.5813, Eval MRR: 0.8426\n",
      "Epoch 29/50 Loss: 0.0063, Eval F1: 0.5833, Eval MRR: 0.8457\n",
      "Epoch 30/50 Loss: 0.0051, Eval F1: 0.5847, Eval MRR: 0.8567\n",
      "Epoch 31/50 Loss: 0.0046, Eval F1: 0.5868, Eval MRR: 0.8618\n",
      "Epoch 32/50 Loss: 0.0044, Eval F1: 0.5844, Eval MRR: 0.8414\n",
      "Epoch 33/50 Loss: 0.0050, Eval F1: 0.5815, Eval MRR: 0.8635\n",
      "Epoch 34/50 Loss: 0.0036, Eval F1: 0.5853, Eval MRR: 0.8594\n",
      "Epoch 35/50 Loss: 0.0037, Eval F1: 0.5828, Eval MRR: 0.8637\n",
      "Epoch 36/50 Loss: 0.0034, Eval F1: 0.5848, Eval MRR: 0.8631\n",
      "Epoch 37/50 Loss: 0.0037, Eval F1: 0.5790, Eval MRR: 0.8399\n",
      "Epoch 38/50 Loss: 0.0040, Eval F1: 0.5839, Eval MRR: 0.8780\n",
      "Epoch 39/50 Loss: 0.0030, Eval F1: 0.5855, Eval MRR: 0.8538\n",
      "Epoch 40/50 Loss: 0.0027, Eval F1: 0.5822, Eval MRR: 0.8540\n",
      "Epoch 41/50 Loss: 0.0030, Eval F1: 0.5858, Eval MRR: 0.8634\n",
      "Epoch 42/50 Loss: 0.0032, Eval F1: 0.5758, Eval MRR: 0.8596\n",
      "Epoch 43/50 Loss: 0.0034, Eval F1: 0.5872, Eval MRR: 0.8651\n",
      "Epoch 44/50 Loss: 0.0036, Eval F1: 0.5870, Eval MRR: 0.8613\n",
      "Epoch 45/50 Loss: 0.0029, Eval F1: 0.5819, Eval MRR: 0.8530\n",
      "Epoch 46/50 Loss: 0.0021, Eval F1: 0.5853, Eval MRR: 0.8613\n",
      "Epoch 47/50 Loss: 0.0022, Eval F1: 0.5875, Eval MRR: 0.8653\n",
      "Epoch 48/50 Loss: 0.0023, Eval F1: 0.5725, Eval MRR: 0.8431\n",
      "Epoch 49/50 Loss: 0.0023, Eval F1: 0.5817, Eval MRR: 0.8666\n",
      "Epoch 50/50 Loss: 0.0023, Eval F1: 0.5864, Eval MRR: 0.8586\n",
      "Final evaluation on development set:\n",
      "Final Eval F1: 0.5864, Final Eval MRR: 0.8586\n",
      "Running optional LLM generation with T5...\n",
      "Generated Answer: Alice Washburn\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader  # Updated import to avoid deprecation warning\n",
    "from torch_geometric.utils import from_networkx, add_self_loops\n",
    "from torch_geometric.nn import SAGEConv, GATConv, GCNConv\n",
    "\n",
    "# -------------------------------\n",
    "# GPU Memory & Determinism Config\n",
    "# -------------------------------\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "main_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "preprocess_device = main_device\n",
    "print(f\"Main device: {main_device}\")\n",
    "print(f\"Preprocessing device: {preprocess_device}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Data Loading\n",
    "# -------------------------------\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_json(\"./Data/train.json\")\n",
    "val_df = pd.read_json(\"./Data/dev.json\")\n",
    "test_df = pd.read_json(\"./Data/test.json\")\n",
    "print(f\"Train samples: {len(train_df)}, Val samples: {len(val_df)}, Test samples: {len(test_df)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Edge Schema & Helper Functions\n",
    "# -------------------------------\n",
    "EDGE_SCHEMA = {\n",
    "    'weight': 0.0,      \n",
    "    'type': 'unknown',  \n",
    "    'type_id': 0,       \n",
    "    'distance': 0,      \n",
    "    'semantic_sim': 0.0,\n",
    "    'keyword_sim': 0.0,  \n",
    "    'query_sim': 0.0     \n",
    "}\n",
    "\n",
    "def add_edge_with_schema(G, u, v, edge_type, **kwargs):\n",
    "    attrs = EDGE_SCHEMA.copy()\n",
    "    attrs['type'] = edge_type\n",
    "    if edge_type == 'sequential':\n",
    "        attrs['type_id'] = 0\n",
    "    elif edge_type == 'keyword':\n",
    "        attrs['type_id'] = 1\n",
    "    elif edge_type == 'semantic':\n",
    "        attrs['type_id'] = 2\n",
    "    elif edge_type == 'query':\n",
    "        attrs['type_id'] = 3\n",
    "    attrs.update(kwargs)\n",
    "    G.add_edge(u, v, **attrs)\n",
    "    return G\n",
    "\n",
    "# -------------------------------\n",
    "# Graph & Embedding Construction\n",
    "# -------------------------------\n",
    "def build_optimized_graph(context, query=None, semantic_threshold=0.6, device=None):\n",
    "    if device is None:\n",
    "        device = preprocess_device\n",
    "        \n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "    G = nx.Graph()\n",
    "    titles = [title for title, _ in context]\n",
    "    texts = [\" \".join(text) if isinstance(text, list) else text for _, text in context]\n",
    "\n",
    "    for title in titles:\n",
    "        G.add_node(title)\n",
    "\n",
    "    with torch.cuda.amp.autocast(enabled=device.type=='cuda'):\n",
    "        with torch.no_grad():\n",
    "            batch_size = 32\n",
    "            all_embeddings = []\n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch_texts = texts[i:i+batch_size]\n",
    "                batch_embeddings = model.encode(batch_texts, convert_to_tensor=True, device=device)\n",
    "                all_embeddings.append(batch_embeddings.cpu())\n",
    "            embeddings = torch.cat(all_embeddings, dim=0)\n",
    "            if query is not None:\n",
    "                query_emb = model.encode(query, convert_to_tensor=True, device=device).cpu()\n",
    "\n",
    "    # Sequential edges\n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i+1, min(i+4, len(titles))):\n",
    "            distance = j - i\n",
    "            weight = np.exp(-distance * 0.5)\n",
    "            add_edge_with_schema(G, titles[i], titles[j], edge_type='sequential', weight=weight, distance=distance)\n",
    "\n",
    "    # Keyword edges\n",
    "    try:\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "        X = tfidf.fit_transform(texts)\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        tfidf_sim = cosine_similarity(X)\n",
    "        flat_tfidf = tfidf_sim.flatten()\n",
    "        tfidf_threshold = max(0.15, np.percentile(flat_tfidf, 75))\n",
    "        for i in range(len(titles)):\n",
    "            for j in range(i+1, len(titles)):\n",
    "                if tfidf_sim[i, j] > tfidf_threshold:\n",
    "                    if not G.has_edge(titles[i], titles[j]):\n",
    "                        add_edge_with_schema(G, titles[i], titles[j], edge_type='keyword',\n",
    "                                             weight=tfidf_sim[i, j], keyword_sim=tfidf_sim[i, j])\n",
    "                    else:\n",
    "                        G[titles[i]][titles[j]]['keyword_sim'] = tfidf_sim[i, j]\n",
    "                        G[titles[i]][titles[j]]['weight'] = max(G[titles[i]][titles[j]]['weight'], tfidf_sim[i, j])\n",
    "    except Exception as e:\n",
    "        print(f\"TF-IDF edge creation failed: {e}\")\n",
    "\n",
    "    # Semantic edges\n",
    "    sim_matrix = torch.zeros((len(titles), len(titles)))\n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i+1, len(titles)):\n",
    "            sim = util.pytorch_cos_sim(embeddings[i], embeddings[j]).item()\n",
    "            sim_matrix[i, j] = sim\n",
    "            sim_matrix[j, i] = sim\n",
    "\n",
    "    if query is not None:\n",
    "        query_sims = torch.zeros(len(titles))\n",
    "        for i in range(len(titles)):\n",
    "            query_sims[i] = util.pytorch_cos_sim(query_emb, embeddings[i]).item()\n",
    "        if query_sims.max() > query_sims.min():\n",
    "            query_sims = (query_sims - query_sims.min()) / (query_sims.max() - query_sims.min())\n",
    "\n",
    "    flat_sims = sim_matrix.flatten()\n",
    "    flat_sims = flat_sims[flat_sims > 0]\n",
    "    if len(flat_sims) > 0:\n",
    "        adapt_threshold = max(semantic_threshold, flat_sims.mean() + 0.5 * flat_sims.std())\n",
    "    else:\n",
    "        adapt_threshold = semantic_threshold\n",
    "\n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i+1, len(titles)):\n",
    "            base_sim = sim_matrix[i, j].item()\n",
    "            if query is not None:\n",
    "                relevance_boost = query_sims[i] * query_sims[j] * 0.2\n",
    "                adjusted_sim = base_sim + relevance_boost\n",
    "            else:\n",
    "                adjusted_sim = base_sim\n",
    "            if adjusted_sim > adapt_threshold:\n",
    "                if not G.has_edge(titles[i], titles[j]):\n",
    "                    add_edge_with_schema(G, titles[i], titles[j], edge_type='semantic',\n",
    "                                         weight=adjusted_sim, semantic_sim=base_sim)\n",
    "                else:\n",
    "                    G[titles[i]][titles[j]]['semantic_sim'] = base_sim\n",
    "                    G[titles[i]][titles[j]]['weight'] = max(G[titles[i]][titles[j]]['weight'], adjusted_sim)\n",
    "\n",
    "    # Query edges\n",
    "    if query is not None:\n",
    "        query_node = \"__QUERY__\"\n",
    "        G.add_node(query_node)\n",
    "        for i, title in enumerate(titles):\n",
    "            sim = query_sims[i].item()\n",
    "            if sim > 0.4:\n",
    "                add_edge_with_schema(G, query_node, title, edge_type='query',\n",
    "                                     weight=sim, query_sim=sim)\n",
    "\n",
    "    edge_counts = {edge_type: 0 for edge_type in [\"sequential\", \"keyword\", \"semantic\", \"query\"]}\n",
    "    for _, _, data in G.edges(data=True):\n",
    "        edge_type = data.get('type', 'unknown')\n",
    "        edge_counts[edge_type] = edge_counts.get(edge_type, 0) + 1\n",
    "    G.graph['edge_counts'] = edge_counts\n",
    "    G.graph['node_count'] = len(G.nodes)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return G, embeddings, titles\n",
    "\n",
    "class FastCachedEmbedder:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n",
    "        if device is None:\n",
    "            device = preprocess_device\n",
    "        self.model = SentenceTransformer(model_name).to(device)\n",
    "        self.device = device\n",
    "        self.passage_cache = {}\n",
    "        self.question_cache = {}\n",
    "        self.use_amp = (device.type == \"cuda\")\n",
    "\n",
    "    def encode_passages(self, texts, batch_size=32):\n",
    "        to_encode = [t for t in texts if t not in self.passage_cache]\n",
    "        if to_encode:\n",
    "            all_embeddings = []\n",
    "            with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "                with torch.no_grad():\n",
    "                    for i in range(0, len(to_encode), batch_size):\n",
    "                        batch_texts = to_encode[i:i+batch_size]\n",
    "                        batch_embs = self.model.encode(batch_texts, convert_to_tensor=True, device=self.device)\n",
    "                        all_embeddings.append(batch_embs.cpu())\n",
    "            if all_embeddings:\n",
    "                all_embs = torch.cat(all_embeddings, dim=0)\n",
    "                for text, emb in zip(to_encode, all_embs):\n",
    "                    self.passage_cache[text] = emb\n",
    "        return [self.passage_cache[t] for t in texts]\n",
    "\n",
    "    def encode_question(self, question):\n",
    "        if question not in self.question_cache:\n",
    "            with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "                with torch.no_grad():\n",
    "                    self.question_cache[question] = self.model.encode(question, convert_to_tensor=True, device=self.device).cpu()\n",
    "        return self.question_cache[question]\n",
    "\n",
    "def create_graph_data(question, context, supporting_titles, embedder):\n",
    "    titles = [title for title, _ in context]\n",
    "    texts = [\" \".join(text) if isinstance(text, list) else text for _, text in context]\n",
    "    \n",
    "    embeddings = embedder.encode_passages(texts)\n",
    "    G, _, _ = build_optimized_graph(context, query=question, device=embedder.device)\n",
    "\n",
    "    node_features = {}\n",
    "    for i, title in enumerate(titles):\n",
    "        emb = embeddings[i]\n",
    "        if not isinstance(emb, torch.Tensor):\n",
    "            emb = torch.as_tensor(emb)\n",
    "        node_features[title] = emb\n",
    "    if \"__QUERY__\" in G.nodes():\n",
    "        query_emb = embedder.encode_question(question)\n",
    "        if not isinstance(query_emb, torch.Tensor):\n",
    "            query_emb = torch.as_tensor(query_emb)\n",
    "        node_features[\"__QUERY__\"] = query_emb\n",
    "    \n",
    "    node_order = list(G.nodes())\n",
    "    data = from_networkx(G)\n",
    "    data.x = torch.stack([node_features[n] for n in node_order if n in node_features])\n",
    "    data.edge_index, _ = add_self_loops(data.edge_index)\n",
    "    \n",
    "    passage_nodes = [n for n in node_order if n != \"__QUERY__\"]\n",
    "    data.titles = passage_nodes\n",
    "    data.supporting_titles = supporting_titles\n",
    "    data.question = question\n",
    "    if \"__QUERY__\" in node_order:\n",
    "        data.query_idx = node_order.index(\"__QUERY__\")\n",
    "    else:\n",
    "        data.query_idx = None\n",
    "    data.num_passage_nodes = len(passage_nodes)\n",
    "    \n",
    "    if \"__QUERY__\" in node_features:\n",
    "        data.question_embedding = node_features[\"__QUERY__\"]\n",
    "    else:\n",
    "        data.question_embedding = embedder.encode_question(question)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def build_dataset(df, embedder, max_samples=None, save_path=None, load_path=None):\n",
    "    if load_path and os.path.exists(load_path):\n",
    "        try:\n",
    "            with open(save_path, 'rb') as f:\n",
    "                print(f\"Loaded dataset from {save_path}\")\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dataset: {e}\")\n",
    "    \n",
    "    if max_samples:\n",
    "        df = df.iloc[:max_samples]\n",
    "    \n",
    "    dataset = []\n",
    "    dataset_type = save_path.split('_')[0] if save_path else \"unknown\"\n",
    "    print(f\"Building {dataset_type} dataset ({len(df)} examples)...\")\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Building {dataset_type} dataset\"):\n",
    "        try:\n",
    "            question = row['question']\n",
    "            context = [tuple(x) for x in row['context']]\n",
    "            if 'supporting_facts' in row and row['supporting_facts']:\n",
    "                supporting = [x[0] for x in row['supporting_facts']]\n",
    "            else:\n",
    "                supporting = []\n",
    "            graph = create_graph_data(question, context, supporting, embedder)\n",
    "            if graph:\n",
    "                dataset.append(graph)\n",
    "            if idx % 50 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing example {idx}: {e}\")\n",
    "            continue\n",
    "    if save_path:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(dataset, f)\n",
    "        print(f\"Saved dataset to {save_path}\")\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Built {dataset_type} dataset with {len(dataset)} examples\")\n",
    "    return dataset\n",
    "\n",
    "# -------------------------------\n",
    "# GNN Model Definition\n",
    "# -------------------------------\n",
    "class F1EnhancedGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3,\n",
    "                 dropout=0.3, aggregation='mean', use_edge_features=False, heads=1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.aggregation = aggregation\n",
    "        self.use_edge_features = use_edge_features\n",
    "        self.heads = heads\n",
    "        \n",
    "        self.input_proj = nn.Linear(in_channels, hidden_channels)\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_ch = hidden_channels\n",
    "            out_ch = hidden_channels\n",
    "            if aggregation == \"attention\":\n",
    "                conv = GATConv(in_ch, out_ch, heads=heads, dropout=dropout, concat=False)\n",
    "            elif use_edge_features:\n",
    "                conv = GCNConv(in_channels, out_ch)\n",
    "            else:\n",
    "                conv = SAGEConv(in_ch, out_ch, aggr=aggregation)\n",
    "            self.convs.append(conv)\n",
    "            self.norms.append(nn.LayerNorm(out_ch))\n",
    "        \n",
    "        self.out_proj = nn.Linear(hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        edge_weight = data.weight if self.use_edge_features and hasattr(data, \"weight\") else None\n",
    "        x = self.input_proj(x)\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            if isinstance(conv, GCNConv) and edge_weight is not None:\n",
    "                x = conv(x, edge_index, edge_weight=edge_weight)\n",
    "            else:\n",
    "                x = conv(x, edge_index)\n",
    "            x = norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------------\n",
    "# Training & Evaluation Functions\n",
    "# -------------------------------\n",
    "def train_model(model, train_dataset, eval_dataset, optimizer, scheduler,\n",
    "                epochs=50, device='cpu', sim_scale=20.0, margin=0.1):\n",
    "    # Create margin ranking loss with parameterized margin.\n",
    "    margin_loss = nn.MarginRankingLoss(margin=margin)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            node_reps = model(batch)\n",
    "            loss = 0.0\n",
    "            for i in range(batch.num_graphs):\n",
    "                node_mask = (batch.batch == i)\n",
    "                reps = node_reps[node_mask]\n",
    "                titles = batch.titles[i]\n",
    "                supporting_titles = batch.supporting_titles[i]\n",
    "                num_passage_nodes = batch.num_passage_nodes[i]\n",
    "                query_idx = batch.query_idx[i] if batch.query_idx[i] is not None else num_passage_nodes\n",
    "                passage_reps = reps[:num_passage_nodes]\n",
    "                query_rep = reps[query_idx]\n",
    "                if query_rep.dim() == 1:\n",
    "                    query_rep = query_rep.unsqueeze(0)\n",
    "                sims = sim_scale * F.cosine_similarity(query_rep, passage_reps, dim=1)\n",
    "                # Determine positives and negatives\n",
    "                pos_indices = [j for j, t in enumerate(titles) if t in supporting_titles]\n",
    "                neg_indices = [j for j, t in enumerate(titles) if t not in supporting_titles]\n",
    "                if len(pos_indices) > 0 and len(neg_indices) > 0:\n",
    "                    pos_scores = sims[pos_indices].unsqueeze(1)\n",
    "                    neg_scores = sims[neg_indices].unsqueeze(0)\n",
    "                    # For margin ranking loss, target should be 1 for positive > negative\n",
    "                    target = torch.ones_like(pos_scores)\n",
    "                    pair_loss = margin_loss(pos_scores, neg_scores, target)\n",
    "                    loss += pair_loss\n",
    "            loss = loss / batch.num_graphs\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        dev_f1, dev_mrr = evaluate_model(model, eval_dataset, device=device, top_k=5, sim_scale=sim_scale)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} Loss: {avg_loss:.4f}, Eval F1: {dev_f1:.4f}, Eval MRR: {dev_mrr:.4f}\")\n",
    "\n",
    "def evaluate_model(model, dataset, device='cpu', top_k=5, sim_scale=20.0):\n",
    "    model.eval()\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    all_f1 = []\n",
    "    all_mrr = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            node_reps = model(batch)\n",
    "            for i in range(batch.num_graphs):\n",
    "                node_mask = (batch.batch == i)\n",
    "                reps = node_reps[node_mask]\n",
    "                titles = batch.titles[i]\n",
    "                supporting_titles = batch.supporting_titles[i]\n",
    "                num_passage_nodes = batch.num_passage_nodes[i]\n",
    "                query_idx = batch.query_idx[i] if batch.query_idx[i] is not None else num_passage_nodes\n",
    "                passage_reps = reps[:num_passage_nodes]\n",
    "                query_rep = reps[query_idx]\n",
    "                if query_rep.dim() == 1:\n",
    "                    query_rep = query_rep.unsqueeze(0)\n",
    "                sims = sim_scale * F.cosine_similarity(query_rep, passage_reps, dim=1)\n",
    "                sorted_indices = torch.argsort(sims, descending=True)\n",
    "                rr = 0.0\n",
    "                for rank, idx in enumerate(sorted_indices, start=1):\n",
    "                    if titles[idx] in supporting_titles:\n",
    "                        rr = 1.0 / rank\n",
    "                        break\n",
    "                all_mrr.append(rr)\n",
    "                retrieved = [titles[idx] for idx in sorted_indices[:top_k]]\n",
    "                true_positives = len(set(retrieved) & set(supporting_titles))\n",
    "                precision = true_positives / top_k\n",
    "                recall = true_positives / len(supporting_titles) if len(supporting_titles) > 0 else 0.0\n",
    "                f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "                all_f1.append(f1)\n",
    "    avg_f1 = sum(all_f1) / len(all_f1) if all_f1 else 0.0\n",
    "    avg_mrr = sum(all_mrr) / len(all_mrr) if all_mrr else 0.0\n",
    "    return avg_f1, avg_mrr\n",
    "\n",
    "# -------------------------------\n",
    "# Optional LLM-based Generation (Bonus)\n",
    "# -------------------------------\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "def generate_answer(question, passages, model_t5, tokenizer, max_length=256):\n",
    "    context_text = \" \".join(passages)\n",
    "    input_text = f\"question: {question} context: {context_text}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(model_t5.device)\n",
    "    outputs = model_t5.generate(input_ids, max_length=max_length)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer\n",
    "\n",
    "# -------------------------------\n",
    "# Hyperparameter Tuning Function\n",
    "# -------------------------------\n",
    "def tune_results(train_dataset, dev_dataset, hyperparams, base_epochs=10):\n",
    "    \"\"\"\n",
    "    Perform grid search over hyperparameters.\n",
    "    hyperparams: dict with keys \"margin\" and \"sim_scale\", each associated with a list of values.\n",
    "    base_epochs: number of epochs to train in each configuration for tuning.\n",
    "    Returns the best hyperparameter combination based on highest eval F1.\n",
    "    \"\"\"\n",
    "    best_f1 = -1.0\n",
    "    best_config = None\n",
    "    results = []\n",
    "    for margin in hyperparams.get(\"margin\", [0.1]):\n",
    "        for sim_scale in hyperparams.get(\"sim_scale\", [20.0]):\n",
    "            print(f\"Tuning with margin={margin}, sim_scale={sim_scale}\")\n",
    "            # Initialize a new model instance and optimizer for each configuration.\n",
    "            model = F1EnhancedGNN(384, 256, 256, num_layers=3, dropout=0.3,\n",
    "                                  aggregation='mean', use_edge_features=False, heads=1).to(main_device)\n",
    "            optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "            # Train for base_epochs epochs.\n",
    "            train_model(model, train_dataset, dev_dataset, optimizer, scheduler,\n",
    "                        epochs=base_epochs, device=main_device, sim_scale=sim_scale, margin=margin)\n",
    "            eval_f1, eval_mrr = evaluate_model(model, dev_dataset, device=main_device, top_k=5, sim_scale=sim_scale)\n",
    "            print(f\"Config margin={margin}, sim_scale={sim_scale}: Eval F1: {eval_f1:.4f}, Eval MRR: {eval_mrr:.4f}\\n\")\n",
    "            results.append(((margin, sim_scale), eval_f1, eval_mrr))\n",
    "            if eval_f1 > best_f1:\n",
    "                best_f1 = eval_f1\n",
    "                best_config = {\"margin\": margin, \"sim_scale\": sim_scale}\n",
    "    print(\"Tuning results:\")\n",
    "    for (margin, sim_scale), f1, mrr in results:\n",
    "        print(f\"Margin: {margin}, SIM_SCALE: {sim_scale} -> F1: {f1:.4f}, MRR: {mrr:.4f}\")\n",
    "    print(f\"Best configuration: {best_config} with F1: {best_f1:.4f}\")\n",
    "    return best_config, results\n",
    "\n",
    "# -------------------------------\n",
    "# Main Routine\n",
    "# -------------------------------\n",
    "def main():\n",
    "    # Increase data points for training and dev\n",
    "    train_dataset = build_dataset(train_df, embedder=FastCachedEmbedder(model_name='all-MiniLM-L6-v2', device=main_device),\n",
    "                                  max_samples=1500, save_path=\"train_dataset.pkl\")\n",
    "    dev_dataset = build_dataset(val_df, embedder=FastCachedEmbedder(model_name='all-MiniLM-L6-v2', device=main_device),\n",
    "                                max_samples=300, save_path=\"dev_dataset.pkl\")\n",
    "    \n",
    "    # Train the model using the best hyperparameters (if tuning has been run) or default values.\n",
    "    best_margin = 0.1\n",
    "    best_sim_scale = 20.0\n",
    "\n",
    "    # Optionally, run tuning.\n",
    "    hyperparams = {\"margin\": [0.05, 0.1, 0.2], \"sim_scale\": [10.0, 20.0, 30.0]}\n",
    "    best_config, tuning_results = tune_results(train_dataset, dev_dataset, hyperparams, base_epochs=10)\n",
    "    best_margin = best_config[\"margin\"]\n",
    "    best_sim_scale = best_config[\"sim_scale\"]\n",
    "\n",
    "    # Initialize final model using the best configuration.\n",
    "    model = F1EnhancedGNN(384, 256, 256, num_layers=3, dropout=0.3, aggregation='mean', use_edge_features=False, heads=1).to(main_device)\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "    \n",
    "    print(\"Starting final training with best hyperparameters...\")\n",
    "    train_model(model, train_dataset, dev_dataset, optimizer, scheduler,\n",
    "                epochs=50, device=main_device, sim_scale=best_sim_scale, margin=best_margin)\n",
    "    \n",
    "    print(\"Final evaluation on development set:\")\n",
    "    final_f1, final_mrr = evaluate_model(model, dev_dataset, device=main_device, top_k=5, sim_scale=best_sim_scale)\n",
    "    print(f\"Final Eval F1: {final_f1:.4f}, Final Eval MRR: {final_mrr:.4f}\")\n",
    "    \n",
    "    print(\"Running optional LLM generation with T5...\")\n",
    "    t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(main_device)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    \n",
    "    sample = dev_dataset[0]\n",
    "    sample = sample.to(main_device)\n",
    "    with torch.no_grad():\n",
    "        sample_rep = model(sample)\n",
    "    titles = sample.titles\n",
    "    num_passage_nodes = sample.num_passage_nodes\n",
    "    query_idx = sample.query_idx if sample.query_idx is not None else num_passage_nodes\n",
    "    passage_reps = sample_rep[:num_passage_nodes]\n",
    "    query_rep = sample_rep[query_idx]\n",
    "    if query_rep.dim() == 1:\n",
    "        query_rep = query_rep.unsqueeze(0)\n",
    "    sims = best_sim_scale * F.cosine_similarity(query_rep, passage_reps, dim=1)\n",
    "    sorted_indices = torch.argsort(sims, descending=True)\n",
    "    top_passages = [titles[idx] for idx in sorted_indices[:5]]\n",
    "    answer = generate_answer(sample.question, top_passages, t5_model, tokenizer)\n",
    "    print(\"Generated Answer:\", answer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94af8a-7be9-4a2d-8d6e-472b7408717f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fafc117-d5be-48f8-83a7-be8a77454adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a8cc10a-5c4c-449f-9310-ea996994616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main device: cuda\n",
      "Preprocessing device: cuda\n",
      "Loading data...\n",
      "Train samples: 167454, Dev samples: 12576\n",
      "Building train dataset (50 examples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c408dd195b42e48daf3c8c5f33e9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building train dataset:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing example 1: expected Tensor as element 1 in argument 0, but got numpy.float64\n",
      "Saved dataset to train_dataset.pkl\n",
      "Built train dataset with 49 examples\n",
      "Building dev dataset (20 examples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee7ab020b8749098c9312cedae0e812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building dev dataset:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing example 2: expected Tensor as element 7 in argument 0, but got float\n",
      "Error processing example 5: expected Tensor as element 4 in argument 0, but got numpy.float64\n",
      "Saved dataset to dev_dataset.pkl\n",
      "Built dev dataset with 18 examples\n",
      "Tuning with margin=0.1, sim_scale=10.0\n",
      "Epoch 1/10 Loss: 0.3650, Eval F1: 0.4550, Eval MRR: 0.8519\n",
      "Epoch 2/10 Loss: 0.2672, Eval F1: 0.4868, Eval MRR: 0.8981\n",
      "Epoch 3/10 Loss: 0.1947, Eval F1: 0.5026, Eval MRR: 0.8690\n",
      "Epoch 4/10 Loss: 0.2104, Eval F1: 0.5150, Eval MRR: 0.8968\n",
      "Epoch 5/10 Loss: 0.1999, Eval F1: 0.4991, Eval MRR: 0.8981\n",
      "Epoch 6/10 Loss: 0.2219, Eval F1: 0.4991, Eval MRR: 0.8981\n",
      "Epoch 7/10 Loss: 0.2061, Eval F1: 0.4832, Eval MRR: 0.8704\n",
      "Epoch 8/10 Loss: 0.2083, Eval F1: 0.4832, Eval MRR: 0.8704\n",
      "Epoch 9/10 Loss: 0.1886, Eval F1: 0.4991, Eval MRR: 0.8444\n",
      "Epoch 10/10 Loss: 0.1672, Eval F1: 0.4832, Eval MRR: 0.8565\n",
      "Config margin=0.1, sim_scale=10.0: Eval F1: 0.4832, Eval MRR: 0.8565\n",
      "\n",
      "Tuning with margin=0.1, sim_scale=20.0\n",
      "Epoch 1/10 Loss: 0.6730, Eval F1: 0.4709, Eval MRR: 0.7963\n",
      "Epoch 2/10 Loss: 0.4999, Eval F1: 0.4868, Eval MRR: 0.8148\n",
      "Epoch 3/10 Loss: 0.4215, Eval F1: 0.5026, Eval MRR: 0.7824\n",
      "Epoch 4/10 Loss: 0.4234, Eval F1: 0.5026, Eval MRR: 0.7731\n",
      "Epoch 5/10 Loss: 0.3406, Eval F1: 0.5026, Eval MRR: 0.7824\n",
      "Epoch 6/10 Loss: 0.3032, Eval F1: 0.5026, Eval MRR: 0.7824\n",
      "Epoch 7/10 Loss: 0.2861, Eval F1: 0.5026, Eval MRR: 0.7731\n",
      "Epoch 8/10 Loss: 0.3416, Eval F1: 0.5062, Eval MRR: 0.7731\n",
      "Epoch 9/10 Loss: 0.2911, Eval F1: 0.5185, Eval MRR: 0.7750\n",
      "Epoch 10/10 Loss: 0.2212, Eval F1: 0.5026, Eval MRR: 0.7704\n",
      "Config margin=0.1, sim_scale=20.0: Eval F1: 0.5026, Eval MRR: 0.7704\n",
      "\n",
      "Tuning with margin=0.1, sim_scale=30.0\n",
      "Epoch 1/10 Loss: 0.9409, Eval F1: 0.4815, Eval MRR: 0.7704\n",
      "Epoch 2/10 Loss: 0.8139, Eval F1: 0.5220, Eval MRR: 0.8000\n",
      "Epoch 3/10 Loss: 0.6305, Eval F1: 0.5062, Eval MRR: 0.8028\n",
      "Epoch 4/10 Loss: 0.4860, Eval F1: 0.5185, Eval MRR: 0.8102\n",
      "Epoch 5/10 Loss: 0.5745, Eval F1: 0.5185, Eval MRR: 0.8194\n",
      "Epoch 6/10 Loss: 0.5742, Eval F1: 0.5185, Eval MRR: 0.8194\n",
      "Epoch 7/10 Loss: 0.3883, Eval F1: 0.5062, Eval MRR: 0.8472\n",
      "Epoch 8/10 Loss: 0.4646, Eval F1: 0.5062, Eval MRR: 0.8102\n",
      "Epoch 9/10 Loss: 0.4721, Eval F1: 0.5062, Eval MRR: 0.8102\n",
      "Epoch 10/10 Loss: 0.3440, Eval F1: 0.4903, Eval MRR: 0.8194\n",
      "Config margin=0.1, sim_scale=30.0: Eval F1: 0.4903, Eval MRR: 0.8194\n",
      "\n",
      "Tuning with margin=0.2, sim_scale=10.0\n",
      "Epoch 1/10 Loss: 0.3698, Eval F1: 0.4533, Eval MRR: 0.7593\n",
      "Epoch 2/10 Loss: 0.3827, Eval F1: 0.4621, Eval MRR: 0.8287\n",
      "Epoch 3/10 Loss: 0.3024, Eval F1: 0.4903, Eval MRR: 0.8657\n",
      "Epoch 4/10 Loss: 0.2861, Eval F1: 0.4780, Eval MRR: 0.9213\n",
      "Epoch 5/10 Loss: 0.3171, Eval F1: 0.4780, Eval MRR: 0.8935\n",
      "Epoch 6/10 Loss: 0.2685, Eval F1: 0.4780, Eval MRR: 0.8935\n",
      "Epoch 7/10 Loss: 0.2726, Eval F1: 0.4780, Eval MRR: 0.8935\n",
      "Epoch 8/10 Loss: 0.2700, Eval F1: 0.4780, Eval MRR: 0.8750\n",
      "Epoch 9/10 Loss: 0.2717, Eval F1: 0.4780, Eval MRR: 0.8935\n",
      "Epoch 10/10 Loss: 0.2441, Eval F1: 0.5220, Eval MRR: 0.8657\n",
      "Config margin=0.2, sim_scale=10.0: Eval F1: 0.5220, Eval MRR: 0.8657\n",
      "\n",
      "Tuning with margin=0.2, sim_scale=20.0\n",
      "Epoch 1/10 Loss: 0.7882, Eval F1: 0.4744, Eval MRR: 0.7361\n",
      "Epoch 2/10 Loss: 0.5638, Eval F1: 0.4744, Eval MRR: 0.7426\n",
      "Epoch 3/10 Loss: 0.4712, Eval F1: 0.5150, Eval MRR: 0.7426\n",
      "Epoch 4/10 Loss: 0.4023, Eval F1: 0.5150, Eval MRR: 0.7380\n",
      "Epoch 5/10 Loss: 0.4335, Eval F1: 0.5150, Eval MRR: 0.7380\n",
      "Epoch 6/10 Loss: 0.2545, Eval F1: 0.5150, Eval MRR: 0.7657\n",
      "Epoch 7/10 Loss: 0.3592, Eval F1: 0.5150, Eval MRR: 0.7380\n",
      "Epoch 8/10 Loss: 0.4134, Eval F1: 0.5026, Eval MRR: 0.7657\n",
      "Epoch 9/10 Loss: 0.4033, Eval F1: 0.5397, Eval MRR: 0.7333\n",
      "Epoch 10/10 Loss: 0.3128, Eval F1: 0.5397, Eval MRR: 0.7981\n",
      "Config margin=0.2, sim_scale=20.0: Eval F1: 0.5397, Eval MRR: 0.7981\n",
      "\n",
      "Tuning with margin=0.2, sim_scale=30.0\n",
      "Epoch 1/10 Loss: 1.2521, Eval F1: 0.4674, Eval MRR: 0.8274\n",
      "Epoch 2/10 Loss: 0.9047, Eval F1: 0.4709, Eval MRR: 0.8148\n",
      "Epoch 3/10 Loss: 0.6456, Eval F1: 0.5026, Eval MRR: 0.8246\n",
      "Epoch 4/10 Loss: 0.5710, Eval F1: 0.5026, Eval MRR: 0.8246\n",
      "Epoch 5/10 Loss: 0.5120, Eval F1: 0.5026, Eval MRR: 0.8246\n",
      "Epoch 6/10 Loss: 0.6517, Eval F1: 0.5026, Eval MRR: 0.8246\n",
      "Epoch 7/10 Loss: 0.5321, Eval F1: 0.5026, Eval MRR: 0.8246\n",
      "Epoch 8/10 Loss: 0.6057, Eval F1: 0.5026, Eval MRR: 0.8153\n",
      "Epoch 9/10 Loss: 0.4907, Eval F1: 0.4903, Eval MRR: 0.8153\n",
      "Epoch 10/10 Loss: 0.4913, Eval F1: 0.4780, Eval MRR: 0.8153\n",
      "Config margin=0.2, sim_scale=30.0: Eval F1: 0.4780, Eval MRR: 0.8153\n",
      "\n",
      "Tuning results:\n",
      "Margin: 0.1, SIM_SCALE: 10.0 -> F1: 0.4832, MRR: 0.8565\n",
      "Margin: 0.1, SIM_SCALE: 20.0 -> F1: 0.5026, MRR: 0.7704\n",
      "Margin: 0.1, SIM_SCALE: 30.0 -> F1: 0.4903, MRR: 0.8194\n",
      "Margin: 0.2, SIM_SCALE: 10.0 -> F1: 0.5220, MRR: 0.8657\n",
      "Margin: 0.2, SIM_SCALE: 20.0 -> F1: 0.5397, MRR: 0.7981\n",
      "Margin: 0.2, SIM_SCALE: 30.0 -> F1: 0.4780, MRR: 0.8153\n",
      "Best configuration: {'margin': 0.2, 'sim_scale': 20.0} with F1: 0.5397\n",
      "Starting final training with best hyperparameters...\n",
      "Epoch 1/50 Loss: 0.7562, Eval F1: 0.5309, Eval MRR: 0.8352\n",
      "Epoch 2/50 Loss: 0.6316, Eval F1: 0.5309, Eval MRR: 0.7685\n",
      "Epoch 3/50 Loss: 0.5055, Eval F1: 0.5026, Eval MRR: 0.7380\n",
      "Epoch 4/50 Loss: 0.4121, Eval F1: 0.5026, Eval MRR: 0.7639\n",
      "Epoch 5/50 Loss: 0.4051, Eval F1: 0.5026, Eval MRR: 0.7917\n",
      "Epoch 6/50 Loss: 0.3976, Eval F1: 0.5026, Eval MRR: 0.7546\n",
      "Epoch 7/50 Loss: 0.4041, Eval F1: 0.5026, Eval MRR: 0.7315\n",
      "Epoch 8/50 Loss: 0.3738, Eval F1: 0.5026, Eval MRR: 0.7593\n",
      "Epoch 9/50 Loss: 0.3457, Eval F1: 0.4903, Eval MRR: 0.6435\n",
      "Epoch 10/50 Loss: 0.2850, Eval F1: 0.4903, Eval MRR: 0.6528\n",
      "Epoch 11/50 Loss: 0.2698, Eval F1: 0.4903, Eval MRR: 0.6574\n",
      "Epoch 12/50 Loss: 0.2672, Eval F1: 0.4621, Eval MRR: 0.6667\n",
      "Epoch 13/50 Loss: 0.2884, Eval F1: 0.4621, Eval MRR: 0.7130\n",
      "Epoch 14/50 Loss: 0.2287, Eval F1: 0.4744, Eval MRR: 0.7130\n",
      "Epoch 15/50 Loss: 0.2869, Eval F1: 0.4744, Eval MRR: 0.6852\n",
      "Epoch 16/50 Loss: 0.2543, Eval F1: 0.4621, Eval MRR: 0.7130\n",
      "Epoch 17/50 Loss: 0.3272, Eval F1: 0.4744, Eval MRR: 0.7222\n",
      "Epoch 18/50 Loss: 0.2925, Eval F1: 0.4744, Eval MRR: 0.6944\n",
      "Epoch 19/50 Loss: 0.2554, Eval F1: 0.4744, Eval MRR: 0.6944\n",
      "Epoch 20/50 Loss: 0.2589, Eval F1: 0.4744, Eval MRR: 0.6852\n",
      "Epoch 21/50 Loss: 0.2477, Eval F1: 0.4744, Eval MRR: 0.6944\n",
      "Epoch 22/50 Loss: 0.2138, Eval F1: 0.4868, Eval MRR: 0.6944\n",
      "Epoch 23/50 Loss: 0.2060, Eval F1: 0.4868, Eval MRR: 0.7222\n",
      "Epoch 24/50 Loss: 0.2139, Eval F1: 0.4868, Eval MRR: 0.7222\n",
      "Epoch 25/50 Loss: 0.2226, Eval F1: 0.4868, Eval MRR: 0.7222\n",
      "Epoch 26/50 Loss: 0.2282, Eval F1: 0.4868, Eval MRR: 0.7222\n",
      "Epoch 27/50 Loss: 0.2129, Eval F1: 0.4868, Eval MRR: 0.7222\n",
      "Epoch 28/50 Loss: 0.2149, Eval F1: 0.4868, Eval MRR: 0.7222\n",
      "Epoch 29/50 Loss: 0.2040, Eval F1: 0.4868, Eval MRR: 0.7222\n",
      "Epoch 30/50 Loss: 0.2168, Eval F1: 0.4744, Eval MRR: 0.7083\n",
      "Epoch 31/50 Loss: 0.2199, Eval F1: 0.4903, Eval MRR: 0.7176\n",
      "Epoch 32/50 Loss: 0.2085, Eval F1: 0.4903, Eval MRR: 0.7546\n",
      "Epoch 33/50 Loss: 0.2034, Eval F1: 0.4780, Eval MRR: 0.7546\n",
      "Epoch 34/50 Loss: 0.2089, Eval F1: 0.4780, Eval MRR: 0.7593\n",
      "Epoch 35/50 Loss: 0.1868, Eval F1: 0.4780, Eval MRR: 0.7500\n",
      "Epoch 36/50 Loss: 0.2000, Eval F1: 0.4780, Eval MRR: 0.7593\n",
      "Epoch 37/50 Loss: 0.2139, Eval F1: 0.4780, Eval MRR: 0.7500\n",
      "Epoch 38/50 Loss: 0.2130, Eval F1: 0.4780, Eval MRR: 0.7778\n",
      "Epoch 39/50 Loss: 0.2173, Eval F1: 0.4780, Eval MRR: 0.7500\n",
      "Epoch 40/50 Loss: 0.2131, Eval F1: 0.4938, Eval MRR: 0.7500\n",
      "Epoch 41/50 Loss: 0.2032, Eval F1: 0.4938, Eval MRR: 0.7500\n",
      "Epoch 42/50 Loss: 0.1981, Eval F1: 0.5062, Eval MRR: 0.7407\n",
      "Epoch 43/50 Loss: 0.1976, Eval F1: 0.5185, Eval MRR: 0.7407\n",
      "Epoch 44/50 Loss: 0.2027, Eval F1: 0.5185, Eval MRR: 0.7407\n",
      "Epoch 45/50 Loss: 0.2087, Eval F1: 0.5185, Eval MRR: 0.7407\n",
      "Epoch 46/50 Loss: 0.1835, Eval F1: 0.5185, Eval MRR: 0.7407\n",
      "Epoch 47/50 Loss: 0.2016, Eval F1: 0.5185, Eval MRR: 0.7407\n",
      "Epoch 48/50 Loss: 0.2068, Eval F1: 0.4938, Eval MRR: 0.7315\n",
      "Epoch 49/50 Loss: 0.1983, Eval F1: 0.5062, Eval MRR: 0.7315\n",
      "Epoch 50/50 Loss: 0.2119, Eval F1: 0.5062, Eval MRR: 0.6852\n",
      "Final GNN Eval F1: 0.5062, Final GNN Eval MRR: 0.6852\n",
      "BM25 Baseline Eval F1: 0.5111, Eval MRR: 0.8350\n",
      "DPR Baseline Eval F1: 0.4524, Eval MRR: 0.9267\n",
      "LLM Generated Answer: Alice Washburn\n",
      "\n",
      "Summary of Results:\n",
      "BM25 Baseline:    F1: 0.5111, MRR: 0.8350\n",
      "DPR Baseline:     F1: 0.4524, MRR: 0.9267\n",
      "GNN Approach:     F1: 0.5062, MRR: 0.6852\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# For BM25 baseline – install via: pip install rank_bm25\n",
    "try:\n",
    "    from rank_bm25 import BM25Okapi\n",
    "except ImportError:\n",
    "    print(\"Please install 'rank_bm25' package for BM25 baseline.\")\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader  # Updated import to avoid deprecation warning\n",
    "from torch_geometric.utils import from_networkx, add_self_loops\n",
    "from torch_geometric.nn import SAGEConv, GATConv, GCNConv\n",
    "\n",
    "###########################\n",
    "# GPU Memory & Determinism Config\n",
    "###########################\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "main_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "preprocess_device = main_device\n",
    "print(f\"Main device: {main_device}\")\n",
    "print(f\"Preprocessing device: {preprocess_device}\")\n",
    "\n",
    "###########################\n",
    "# Data Loading\n",
    "###########################\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_json(\"./Data/train.json\")\n",
    "dev_df_full = pd.read_json(\"./Data/dev.json\")  # For baselines, we use raw JSON data.\n",
    "print(f\"Train samples: {len(train_df)}, Dev samples: {len(dev_df_full)}\")\n",
    "\n",
    "###########################\n",
    "# Edge Schema & Helper Functions\n",
    "###########################\n",
    "EDGE_SCHEMA = {\n",
    "    'weight': 0.0,\n",
    "    'type': 'unknown',\n",
    "    'type_id': 0,\n",
    "    'distance': 0,\n",
    "    'semantic_sim': 0.0,\n",
    "    'keyword_sim': 0.0,\n",
    "    'query_sim': 0.0\n",
    "}\n",
    "\n",
    "def add_edge_with_schema(G, u, v, edge_type, **kwargs):\n",
    "    attrs = EDGE_SCHEMA.copy()\n",
    "    attrs['type'] = edge_type\n",
    "    if edge_type == 'sequential':\n",
    "        attrs['type_id'] = 0\n",
    "    elif edge_type == 'keyword':\n",
    "        attrs['type_id'] = 1\n",
    "    elif edge_type == 'semantic':\n",
    "        attrs['type_id'] = 2\n",
    "    elif edge_type == 'query':\n",
    "        attrs['type_id'] = 3\n",
    "    attrs.update(kwargs)\n",
    "    G.add_edge(u, v, **attrs)\n",
    "    return G\n",
    "\n",
    "###########################\n",
    "# Graph & Embedding Construction for GNN Approach\n",
    "###########################\n",
    "def build_optimized_graph(context, query=None, semantic_threshold=0.6, device=None):\n",
    "    if device is None:\n",
    "        device = preprocess_device\n",
    "        \n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "    G = nx.Graph()\n",
    "    titles = [title for title, _ in context]\n",
    "    texts = [\" \".join(text) if isinstance(text, list) else text for _, text in context]\n",
    "\n",
    "    for title in titles:\n",
    "        G.add_node(title)\n",
    "    \n",
    "    with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
    "        with torch.no_grad():\n",
    "            batch_size = 32\n",
    "            all_embeddings = []\n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch_texts = texts[i:i+batch_size]\n",
    "                batch_embeddings = model.encode(batch_texts, convert_to_tensor=True, device=device)\n",
    "                all_embeddings.append(batch_embeddings.cpu())\n",
    "            embeddings = torch.cat(all_embeddings, dim=0)\n",
    "            if query is not None:\n",
    "                query_emb = model.encode(query, convert_to_tensor=True, device=device).cpu()\n",
    "\n",
    "    # Sequential edges\n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i+1, min(i+4, len(titles))):\n",
    "            distance = j - i\n",
    "            weight = np.exp(-distance * 0.5)\n",
    "            add_edge_with_schema(G, titles[i], titles[j], edge_type='sequential', weight=weight, distance=distance)\n",
    "\n",
    "    # Keyword edges\n",
    "    try:\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "        X = tfidf.fit_transform(texts)\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        tfidf_sim = cosine_similarity(X)\n",
    "        flat_tfidf = tfidf_sim.flatten()\n",
    "        tfidf_threshold = max(0.15, np.percentile(flat_tfidf, 75))\n",
    "        for i in range(len(titles)):\n",
    "            for j in range(i+1, len(titles)):\n",
    "                if tfidf_sim[i, j] > tfidf_threshold:\n",
    "                    if not G.has_edge(titles[i], titles[j]):\n",
    "                        add_edge_with_schema(G, titles[i], titles[j], edge_type='keyword', weight=tfidf_sim[i, j], keyword_sim=tfidf_sim[i, j])\n",
    "                    else:\n",
    "                        G[titles[i]][titles[j]]['keyword_sim'] = tfidf_sim[i, j]\n",
    "                        G[titles[i]][titles[j]]['weight'] = max(G[titles[i]][titles[j]]['weight'], tfidf_sim[i, j])\n",
    "    except Exception as e:\n",
    "        print(f\"TF-IDF edge creation failed: {e}\")\n",
    "\n",
    "    # Semantic similarity edges\n",
    "    sim_matrix = torch.zeros((len(titles), len(titles)))\n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i+1, len(titles)):\n",
    "            sim = util.pytorch_cos_sim(embeddings[i], embeddings[j]).item()\n",
    "            sim_matrix[i, j] = sim\n",
    "            sim_matrix[j, i] = sim\n",
    "\n",
    "    if query is not None:\n",
    "        query_sims = torch.zeros(len(titles))\n",
    "        for i in range(len(titles)):\n",
    "            query_sims[i] = util.pytorch_cos_sim(query_emb, embeddings[i]).item()\n",
    "        if query_sims.max() > query_sims.min():\n",
    "            query_sims = (query_sims - query_sims.min()) / (query_sims.max() - query_sims.min())\n",
    "\n",
    "    flat_sims = sim_matrix.flatten()[sim_matrix.flatten() > 0]\n",
    "    if len(flat_sims) > 0:\n",
    "        adapt_threshold = max(semantic_threshold, flat_sims.mean() + 0.5 * flat_sims.std())\n",
    "    else:\n",
    "        adapt_threshold = semantic_threshold\n",
    "\n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i+1, len(titles)):\n",
    "            base_sim = sim_matrix[i, j].item()\n",
    "            if query is not None:\n",
    "                relevance_boost = query_sims[i] * query_sims[j] * 0.2\n",
    "                adjusted_sim = base_sim + relevance_boost\n",
    "            else:\n",
    "                adjusted_sim = base_sim\n",
    "            if adjusted_sim > adapt_threshold:\n",
    "                if not G.has_edge(titles[i], titles[j]):\n",
    "                    add_edge_with_schema(G, titles[i], titles[j], edge_type='semantic', weight=adjusted_sim, semantic_sim=base_sim)\n",
    "                else:\n",
    "                    G[titles[i]][titles[j]]['semantic_sim'] = base_sim\n",
    "                    G[titles[i]][titles[j]]['weight'] = max(G[titles[i]][titles[j]]['weight'], adjusted_sim)\n",
    "\n",
    "    # Query edges\n",
    "    if query is not None:\n",
    "        query_node = \"__QUERY__\"\n",
    "        G.add_node(query_node)\n",
    "        for i, title in enumerate(titles):\n",
    "            sim = query_sims[i].item()\n",
    "            if sim > 0.4:\n",
    "                add_edge_with_schema(G, query_node, title, edge_type='query', weight=sim, query_sim=sim)\n",
    "\n",
    "    edge_counts = {etype: 0 for etype in [\"sequential\", \"keyword\", \"semantic\", \"query\"]}\n",
    "    for _, _, data in G.edges(data=True):\n",
    "        etype = data.get('type', 'unknown')\n",
    "        edge_counts[etype] += 1\n",
    "    G.graph['edge_counts'] = edge_counts\n",
    "    G.graph['node_count'] = len(G.nodes)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return G, embeddings, titles\n",
    "\n",
    "class FastCachedEmbedder:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n",
    "        if device is None:\n",
    "            device = preprocess_device\n",
    "        self.model = SentenceTransformer(model_name).to(device)\n",
    "        self.device = device\n",
    "        self.passage_cache = {}\n",
    "        self.question_cache = {}\n",
    "        self.use_amp = (device.type == \"cuda\")\n",
    "\n",
    "    def encode_passages(self, texts, batch_size=32):\n",
    "        to_encode = [t for t in texts if t not in self.passage_cache]\n",
    "        if to_encode:\n",
    "            all_embeddings = []\n",
    "            with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "                with torch.no_grad():\n",
    "                    for i in range(0, len(to_encode), batch_size):\n",
    "                        batch_texts = to_encode[i:i+batch_size]\n",
    "                        batch_embs = self.model.encode(batch_texts, convert_to_tensor=True, device=self.device)\n",
    "                        all_embeddings.append(batch_embs.cpu())\n",
    "            if all_embeddings:\n",
    "                all_embs = torch.cat(all_embeddings, dim=0)\n",
    "                for text, emb in zip(to_encode, all_embs):\n",
    "                    self.passage_cache[text] = emb\n",
    "        # Ensure conversion to float tensor\n",
    "        return [torch.tensor(self.passage_cache[t], dtype=torch.float) if not torch.is_tensor(self.passage_cache[t]) else self.passage_cache[t] for t in texts]\n",
    "\n",
    "    def encode_question(self, question):\n",
    "        if question not in self.question_cache:\n",
    "            with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "                with torch.no_grad():\n",
    "                    self.question_cache[question] = self.model.encode(question, convert_to_tensor=True, device=self.device).cpu()\n",
    "        # Ensure tensor is float\n",
    "        q = self.question_cache[question]\n",
    "        return q if torch.is_tensor(q) else torch.tensor(q, dtype=torch.float)\n",
    "\n",
    "def create_graph_data(question, context, supporting_titles, embedder):\n",
    "    titles = [title for title, _ in context]\n",
    "    texts = [\" \".join(text) if isinstance(text, list) else text for _, text in context]\n",
    "    embeddings = embedder.encode_passages(texts)\n",
    "    G, _, _ = build_optimized_graph(context, query=question, device=embedder.device)\n",
    "    \n",
    "    node_features = {}\n",
    "    for i, title in enumerate(titles):\n",
    "        emb = embeddings[i]\n",
    "        # Ensure tensor conversion:\n",
    "        if not torch.is_tensor(emb):\n",
    "            emb = torch.tensor(emb, dtype=torch.float)\n",
    "        node_features[title] = emb\n",
    "    if \"__QUERY__\" in G.nodes():\n",
    "        query_emb = embedder.encode_question(question)\n",
    "        if not torch.is_tensor(query_emb):\n",
    "            query_emb = torch.tensor(query_emb, dtype=torch.float)\n",
    "        node_features[\"__QUERY__\"] = query_emb\n",
    "    \n",
    "    node_order = list(G.nodes())\n",
    "    data = from_networkx(G)\n",
    "    data.x = torch.stack([node_features[n] for n in node_order if n in node_features])\n",
    "    data.edge_index, _ = add_self_loops(data.edge_index)\n",
    "    passage_nodes = [n for n in node_order if n != \"__QUERY__\"]\n",
    "    data.titles = passage_nodes\n",
    "    data.supporting_titles = supporting_titles\n",
    "    data.question = question\n",
    "    data.query_idx = node_order.index(\"__QUERY__\") if \"__QUERY__\" in node_order else None\n",
    "    data.num_passage_nodes = len(passage_nodes)\n",
    "    if \"__QUERY__\" in node_features:\n",
    "        data.question_embedding = node_features[\"__QUERY__\"]\n",
    "    else:\n",
    "        data.question_embedding = embedder.encode_question(question)\n",
    "    return data\n",
    "\n",
    "def build_dataset(df, embedder, max_samples=None, save_path=None, load_path=None):\n",
    "    if load_path and os.path.exists(save_path):\n",
    "        try:\n",
    "            with open(save_path, 'rb') as f:\n",
    "                print(f\"Loaded dataset from {save_path}\")\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dataset: {e}\")\n",
    "    if max_samples:\n",
    "        df = df.iloc[:max_samples]\n",
    "    dataset = []\n",
    "    dataset_type = save_path.split('_')[0] if save_path else \"unknown\"\n",
    "    print(f\"Building {dataset_type} dataset ({len(df)} examples)...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Building {dataset_type} dataset\"):\n",
    "        try:\n",
    "            question = row['question']\n",
    "            context = [tuple(x) for x in row['context']]\n",
    "            supporting = [x[0] for x in row['supporting_facts']] if 'supporting_facts' in row and row['supporting_facts'] else []\n",
    "            graph = create_graph_data(question, context, supporting, embedder)\n",
    "            if graph:\n",
    "                dataset.append(graph)\n",
    "            if idx % 50 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing example {idx}: {e}\")\n",
    "            continue\n",
    "    if save_path:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(dataset, f)\n",
    "        print(f\"Saved dataset to {save_path}\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Built {dataset_type} dataset with {len(dataset)} examples\")\n",
    "    return dataset\n",
    "\n",
    "###########################\n",
    "# GNN Model Definition\n",
    "###########################\n",
    "class F1EnhancedGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3,\n",
    "                 dropout=0.3, aggregation='mean', use_edge_features=False, heads=1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.aggregation = aggregation\n",
    "        self.use_edge_features = use_edge_features\n",
    "        self.heads = heads\n",
    "        self.input_proj = nn.Linear(in_channels, hidden_channels)\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_ch = hidden_channels\n",
    "            out_ch = hidden_channels\n",
    "            if aggregation == \"attention\":\n",
    "                conv = GATConv(in_ch, out_ch, heads=heads, dropout=dropout, concat=False)\n",
    "            elif use_edge_features:\n",
    "                conv = GCNConv(in_channels, out_ch)\n",
    "            else:\n",
    "                conv = SAGEConv(in_ch, out_ch, aggr=aggregation)\n",
    "            self.convs.append(conv)\n",
    "            self.norms.append(nn.LayerNorm(out_ch))\n",
    "        self.out_proj = nn.Linear(hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        edge_weight = data.weight if self.use_edge_features and hasattr(data, \"weight\") else None\n",
    "        x = self.input_proj(x)\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            if isinstance(conv, GCNConv) and edge_weight is not None:\n",
    "                x = conv(x, edge_index, edge_weight=edge_weight)\n",
    "            else:\n",
    "                x = conv(x, edge_index)\n",
    "            x = norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "###########################\n",
    "# Training & Evaluation Functions for GNN\n",
    "###########################\n",
    "def train_model(model, train_dataset, eval_dataset, optimizer, scheduler,\n",
    "                epochs=50, device='cpu', sim_scale=20.0, margin=0.2):\n",
    "    margin_loss = nn.MarginRankingLoss(margin=margin)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            node_reps = model(batch)\n",
    "            loss = 0.0\n",
    "            for i in range(batch.num_graphs):\n",
    "                node_mask = (batch.batch == i)\n",
    "                reps = node_reps[node_mask]\n",
    "                titles = batch.titles[i]\n",
    "                supporting_titles = batch.supporting_titles[i]\n",
    "                num_passage_nodes = batch.num_passage_nodes[i]\n",
    "                query_idx = batch.query_idx[i] if batch.query_idx[i] is not None else num_passage_nodes\n",
    "                passage_reps = reps[:num_passage_nodes]\n",
    "                query_rep = reps[query_idx]\n",
    "                if query_rep.dim() == 1:\n",
    "                    query_rep = query_rep.unsqueeze(0)\n",
    "                sims = sim_scale * F.cosine_similarity(query_rep, passage_reps, dim=1)\n",
    "                pos_indices = [j for j, t in enumerate(titles) if t in supporting_titles]\n",
    "                neg_indices = [j for j, t in enumerate(titles) if t not in supporting_titles]\n",
    "                if len(pos_indices) > 0 and len(neg_indices) > 0:\n",
    "                    pos_scores = sims[pos_indices].unsqueeze(1)\n",
    "                    neg_scores = sims[neg_indices].unsqueeze(0)\n",
    "                    target = torch.ones_like(pos_scores)\n",
    "                    pair_loss = margin_loss(pos_scores, neg_scores, target)\n",
    "                    loss += pair_loss\n",
    "            loss = loss / batch.num_graphs\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        dev_f1, dev_mrr = evaluate_model(model, eval_dataset, device=device, top_k=5, sim_scale=sim_scale)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} Loss: {avg_loss:.4f}, Eval F1: {dev_f1:.4f}, Eval MRR: {dev_mrr:.4f}\")\n",
    "        \n",
    "def evaluate_model(model, dataset, device='cpu', top_k=5, sim_scale=20.0):\n",
    "    model.eval()\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    all_f1, all_mrr = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            node_reps = model(batch)\n",
    "            for i in range(batch.num_graphs):\n",
    "                node_mask = (batch.batch == i)\n",
    "                reps = node_reps[node_mask]\n",
    "                titles = batch.titles[i]\n",
    "                supporting_titles = batch.supporting_titles[i]\n",
    "                num_passage_nodes = batch.num_passage_nodes[i]\n",
    "                query_idx = batch.query_idx[i] if batch.query_idx[i] is not None else num_passage_nodes\n",
    "                passage_reps = reps[:num_passage_nodes]\n",
    "                query_rep = reps[query_idx]\n",
    "                if query_rep.dim() == 1:\n",
    "                    query_rep = query_rep.unsqueeze(0)\n",
    "                sims = sim_scale * F.cosine_similarity(query_rep, passage_reps, dim=1)\n",
    "                sorted_indices = torch.argsort(sims, descending=True)\n",
    "                rr = 0.0\n",
    "                for rank, idx in enumerate(sorted_indices, start=1):\n",
    "                    if titles[idx] in supporting_titles:\n",
    "                        rr = 1.0 / rank\n",
    "                        break\n",
    "                all_mrr.append(rr)\n",
    "                retrieved = [titles[idx] for idx in sorted_indices[:top_k]]\n",
    "                true_positives = len(set(retrieved) & set(supporting_titles))\n",
    "                precision = true_positives / top_k\n",
    "                recall = true_positives / len(supporting_titles) if len(supporting_titles) > 0 else 0.0\n",
    "                f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "                all_f1.append(f1)\n",
    "    avg_f1 = sum(all_f1) / len(all_f1) if all_f1 else 0.0\n",
    "    avg_mrr = sum(all_mrr) / len(all_mrr) if all_mrr else 0.0\n",
    "    return avg_f1, avg_mrr\n",
    "\n",
    "###########################\n",
    "# Baseline Evaluation Functions (BM25 and DPR)\n",
    "###########################\n",
    "def evaluate_baseline_bm25(df, top_k=5):\n",
    "    \"\"\"Evaluate BM25 baseline on raw dev dataframe (only first max_samples examples)\"\"\"\n",
    "    total_f1, total_mrr = 0.0, 0.0\n",
    "    n = 0\n",
    "    # Use simple whitespace tokenization for BM25\n",
    "    for idx, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        context = row['context']  # Each element: [title, list of sentences]\n",
    "        supporting = [fact[0] for fact in row['supporting_facts']] if 'supporting_facts' in row and row['supporting_facts'] else []\n",
    "        passages = []\n",
    "        titles = []\n",
    "        for title, sentences in context:\n",
    "            merged = \" \".join(sentences) if isinstance(sentences, list) else sentences\n",
    "            passages.append(merged.lower())\n",
    "            titles.append(title)\n",
    "        if len(passages) == 0:\n",
    "            continue\n",
    "        bm25 = BM25Okapi([doc.split() for doc in passages])\n",
    "        scores = bm25.get_scores(question.lower().split())\n",
    "        ranked_indices = np.argsort(scores)[::-1]\n",
    "        # Compute MRR\n",
    "        rr = 0.0\n",
    "        for rank, idx in enumerate(ranked_indices, start=1):\n",
    "            if titles[idx] in supporting:\n",
    "                rr = 1.0 / rank\n",
    "                break\n",
    "        # Compute F1 for top_k ranked passages\n",
    "        retrieved = [titles[idx] for idx in ranked_indices[:top_k]]\n",
    "        true_positives = len(set(retrieved) & set(supporting))\n",
    "        precision = true_positives / top_k if top_k > 0 else 0.0\n",
    "        recall = true_positives / len(supporting) if len(supporting) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision+recall) > 0 else 0.0\n",
    "        total_f1 += f1\n",
    "        total_mrr += rr\n",
    "        n += 1\n",
    "    return total_f1/n if n > 0 else 0.0, total_mrr/n if n > 0 else 0.0\n",
    "\n",
    "def evaluate_baseline_dpr(df, model_dpr, top_k=5):\n",
    "    \"\"\"Evaluate DPR baseline on raw dev dataframe using SentenceTransformer for dense retrieval.\"\"\"\n",
    "    total_f1, total_mrr = 0.0, 0.0\n",
    "    n = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        context = row['context']\n",
    "        supporting = [fact[0] for fact in row['supporting_facts']] if 'supporting_facts' in row and row['supporting_facts'] else []\n",
    "        passages = []\n",
    "        titles = []\n",
    "        for title, sentences in context:\n",
    "            merged = \" \".join(sentences) if isinstance(sentences, list) else sentences\n",
    "            passages.append(merged)\n",
    "            titles.append(title)\n",
    "        if len(passages) == 0:\n",
    "            continue\n",
    "        q_emb = model_dpr.encode([question], convert_to_tensor=True)\n",
    "        p_embs = model_dpr.encode(passages, convert_to_tensor=True)\n",
    "        sims = F.cosine_similarity(q_emb, p_embs)\n",
    "        sims = sims.cpu().numpy()\n",
    "        ranked_indices = np.argsort(sims)[::-1]\n",
    "        rr = 0.0\n",
    "        for rank, idx in enumerate(ranked_indices, start=1):\n",
    "            if titles[idx] in supporting:\n",
    "                rr = 1.0 / rank\n",
    "                break\n",
    "        retrieved = [titles[idx] for idx in ranked_indices[:top_k]]\n",
    "        true_positives = len(set(retrieved) & set(supporting))\n",
    "        precision = true_positives / top_k if top_k > 0 else 0.0\n",
    "        recall = true_positives / len(supporting) if len(supporting) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision+recall) if (precision+recall) > 0 else 0.0\n",
    "        total_f1 += f1\n",
    "        total_mrr += rr\n",
    "        n += 1\n",
    "    return total_f1/n if n>0 else 0.0, total_mrr/n if n>0 else 0.0\n",
    "\n",
    "###########################\n",
    "# Hyperparameter Tuning Function for GNN\n",
    "###########################\n",
    "def tune_results(train_dataset, dev_dataset, hyperparams, base_epochs=10):\n",
    "    best_f1 = -1.0\n",
    "    best_config = None\n",
    "    results = []\n",
    "    for margin in hyperparams.get(\"margin\", [0.1]):\n",
    "        for sim_scale in hyperparams.get(\"sim_scale\", [20.0]):\n",
    "            print(f\"Tuning with margin={margin}, sim_scale={sim_scale}\")\n",
    "            model = F1EnhancedGNN(384, 256, 256, num_layers=3, dropout=0.3,\n",
    "                                  aggregation='mean', use_edge_features=False, heads=1).to(main_device)\n",
    "            optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "            train_model(model, train_dataset, dev_dataset, optimizer, scheduler,\n",
    "                        epochs=base_epochs, device=main_device, sim_scale=sim_scale, margin=margin)\n",
    "            eval_f1, eval_mrr = evaluate_model(model, dev_dataset, device=main_device, top_k=5, sim_scale=sim_scale)\n",
    "            print(f\"Config margin={margin}, sim_scale={sim_scale}: Eval F1: {eval_f1:.4f}, Eval MRR: {eval_mrr:.4f}\\n\")\n",
    "            results.append(((margin, sim_scale), eval_f1, eval_mrr))\n",
    "            if eval_f1 > best_f1:\n",
    "                best_f1 = eval_f1\n",
    "                best_config = {\"margin\": margin, \"sim_scale\": sim_scale}\n",
    "    print(\"Tuning results:\")\n",
    "    for (margin, sim_scale), f1, mrr in results:\n",
    "        print(f\"Margin: {margin}, SIM_SCALE: {sim_scale} -> F1: {f1:.4f}, MRR: {mrr:.4f}\")\n",
    "    print(f\"Best configuration: {best_config} with F1: {best_f1:.4f}\")\n",
    "    return best_config, results\n",
    "\n",
    "###########################\n",
    "# Main Routine\n",
    "###########################\n",
    "def main():\n",
    "    # Use 50 samples for training and 20 for dev as specified.\n",
    "    embedder_for_graph = FastCachedEmbedder(model_name='all-MiniLM-L6-v2', device=main_device)\n",
    "    train_dataset = build_dataset(train_df, embedder=embedder_for_graph,\n",
    "                                  max_samples=50, save_path=\"train_dataset.pkl\")\n",
    "    dev_dataset = build_dataset(dev_df_full, embedder=embedder_for_graph,\n",
    "                                max_samples=20, save_path=\"dev_dataset.pkl\")\n",
    "    \n",
    "    # For baselines, take the first 20 examples from dev_df.\n",
    "    dev_df = dev_df_full.iloc[:20]\n",
    "    \n",
    "    # Hyperparameter tuning for GNN retrieval: grid over margin and sim_scale.\n",
    "    hyperparams = {\"margin\": [0.1, 0.2], \"sim_scale\": [10.0, 20.0, 30.0]}\n",
    "    best_config, tuning_results = tune_results(train_dataset, dev_dataset, hyperparams, base_epochs=10)\n",
    "    best_margin = best_config[\"margin\"]\n",
    "    best_sim_scale = best_config[\"sim_scale\"]\n",
    "    \n",
    "    # Final training of the GNN model with best hyperparameters.\n",
    "    model = F1EnhancedGNN(384, 256, 256, num_layers=3, dropout=0.3,\n",
    "                          aggregation='mean', use_edge_features=False, heads=1).to(main_device)\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "    print(\"Starting final training with best hyperparameters...\")\n",
    "    train_model(model, train_dataset, dev_dataset, optimizer, scheduler,\n",
    "                epochs=50, device=main_device, sim_scale=best_sim_scale, margin=best_margin)\n",
    "    \n",
    "    final_f1, final_mrr = evaluate_model(model, dev_dataset, device=main_device, top_k=5, sim_scale=best_sim_scale)\n",
    "    print(f\"Final GNN Eval F1: {final_f1:.4f}, Final GNN Eval MRR: {final_mrr:.4f}\")\n",
    "    \n",
    "    # Baseline BM25 evaluation:\n",
    "    bm25_f1, bm25_mrr = evaluate_baseline_bm25(dev_df, top_k=5)\n",
    "    print(f\"BM25 Baseline Eval F1: {bm25_f1:.4f}, Eval MRR: {bm25_mrr:.4f}\")\n",
    "    \n",
    "    # Baseline DPR evaluation:\n",
    "    model_dpr = SentenceTransformer('all-MiniLM-L6-v2', device=main_device)\n",
    "    dpr_f1, dpr_mrr = evaluate_baseline_dpr(dev_df, model_dpr, top_k=5)\n",
    "    print(f\"DPR Baseline Eval F1: {dpr_f1:.4f}, Eval MRR: {dpr_mrr:.4f}\")\n",
    "    \n",
    "    # Optional LLM Generation using T5:\n",
    "    from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "    t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(main_device)\n",
    "    t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    sample = dev_dataset[0]\n",
    "    sample = sample.to(main_device)\n",
    "    with torch.no_grad():\n",
    "        sample_rep = model(sample)\n",
    "    titles = sample.titles\n",
    "    num_passage_nodes = sample.num_passage_nodes\n",
    "    query_idx = sample.query_idx if sample.query_idx is not None else num_passage_nodes\n",
    "    passage_reps = sample_rep[:num_passage_nodes]\n",
    "    query_rep = sample_rep[query_idx]\n",
    "    if query_rep.dim() == 1:\n",
    "        query_rep = query_rep.unsqueeze(0)\n",
    "    sims = best_sim_scale * F.cosine_similarity(query_rep, passage_reps, dim=1)\n",
    "    sorted_indices = torch.argsort(sims, descending=True)\n",
    "    top_passages = [titles[idx] for idx in sorted_indices[:5]]\n",
    "    answer = generate_answer(sample.question, top_passages, t5_model, t5_tokenizer)\n",
    "    print(\"LLM Generated Answer:\", answer)\n",
    "    \n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(f\"BM25 Baseline:    F1: {bm25_f1:.4f}, MRR: {bm25_mrr:.4f}\")\n",
    "    print(f\"DPR Baseline:     F1: {dpr_f1:.4f}, MRR: {dpr_mrr:.4f}\")\n",
    "    print(f\"GNN Approach:     F1: {final_f1:.4f}, MRR: {final_mrr:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21fcaa4-c4b4-4c21-a5a4-d08010340a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847d232-9b7c-48ed-9dcb-40fa45db1dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e648c45-383d-46ee-b0ef-766e4d8e8604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main device: cuda\n",
      "Preprocessing device: cuda\n",
      "Loading data...\n",
      "Train samples: 167454, Dev samples: 12576\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 590\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBetterGNN Approach: F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MRR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_mrr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 590\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 529\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;66;03m# Use 1500 samples for training and 300 for dev for final training; \u001b[39;00m\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;66;03m# for final reported experiments, you might later use full data.\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m     embedder \u001b[38;5;241m=\u001b[39m \u001b[43mFastCachedEmbedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m build_dataset(train_df, embedder\u001b[38;5;241m=\u001b[39membedder, max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m, save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dataset.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    531\u001b[0m     dev_dataset \u001b[38;5;241m=\u001b[39m build_dataset(dev_df, embedder\u001b[38;5;241m=\u001b[39membedder, max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_dataset.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 195\u001b[0m, in \u001b[0;36mFastCachedEmbedder.__init__\u001b[0;34m(self, model_name, device)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     device \u001b[38;5;241m=\u001b[39m preprocess_device\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpassage_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py:308\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    299\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[1;32m    302\u001b[0m     model_name_or_path,\n\u001b[1;32m    303\u001b[0m     token,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    307\u001b[0m ):\n\u001b[0;32m--> 308\u001b[0m     modules, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[1;32m    321\u001b[0m         model_name_or_path,\n\u001b[1;32m    322\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[1;32m    330\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py:1739\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[1;32m   1736\u001b[0m \u001b[38;5;66;03m# Try to initialize the module with a lot of kwargs, but only if the module supports them\u001b[39;00m\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;66;03m# Otherwise we fall back to the load method\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1741\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class\u001b[38;5;241m.\u001b[39mload(model_name_or_path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Transformer.py:80\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     config_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 80\u001b[0m config, is_peft_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Transformer.py:145\u001b[0m, in \u001b[0;36mTransformer._load_config\u001b[0;34m(self, model_name_or_path, cache_dir, backend, config_args)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeftConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py:1069\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1066\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1067\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1069\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1071\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:591\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:650\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    665\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:363\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    378\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:860\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    842\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    858\u001b[0m     )\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:923\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[1;32m    921\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m (url_to_download, etag, commit_hash, expected_size, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1374\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1294\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1291\u001b[0m hf_headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1294\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:278\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 278\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m399\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:301\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py:93\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:666\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    665\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 666\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:377\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:1001\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1001\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[1;32m   1004\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1005\u001b[0m         (\n\u001b[1;32m   1006\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1012\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:314\u001b[0m, in \u001b[0;36mVerifiedHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# Google App Engine's httplib does not define _tunnel_host\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:159\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocket_options\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[1;32m    168\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py:74\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m     73\u001b[0m         sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 74\u001b[0m     \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sock\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# For BM25 baseline – install via: pip install rank_bm25\n",
    "try:\n",
    "    from rank_bm25 import BM25Okapi\n",
    "except ImportError:\n",
    "    print(\"Please install 'rank_bm25' package for BM25 baseline.\")\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader  # Updated import\n",
    "from torch_geometric.utils import from_networkx, add_self_loops\n",
    "from torch_geometric.nn import SAGEConv, GATConv, GCNConv\n",
    "\n",
    "###########################\n",
    "# GPU Memory & Determinism Config\n",
    "###########################\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "main_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "preprocess_device = main_device\n",
    "print(f\"Main device: {main_device}\")\n",
    "print(f\"Preprocessing device: {preprocess_device}\")\n",
    "\n",
    "###########################\n",
    "# Data Loading\n",
    "###########################\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_json(\"./Data/train.json\")\n",
    "dev_df = pd.read_json(\"./Data/dev.json\")\n",
    "print(f\"Train samples: {len(train_df)}, Dev samples: {len(dev_df)}\")\n",
    "\n",
    "###########################\n",
    "# Edge Schema & Helper Functions\n",
    "###########################\n",
    "EDGE_SCHEMA = {\n",
    "    'weight': 0.0,\n",
    "    'type': 'unknown',\n",
    "    'type_id': 0,\n",
    "    'distance': 0,\n",
    "    'semantic_sim': 0.0,\n",
    "    'keyword_sim': 0.0,\n",
    "    'query_sim': 0.0\n",
    "}\n",
    "\n",
    "def add_edge_with_schema(G, u, v, edge_type, **kwargs):\n",
    "    attrs = EDGE_SCHEMA.copy()\n",
    "    attrs['type'] = edge_type\n",
    "    if edge_type == 'sequential':\n",
    "        attrs['type_id'] = 0\n",
    "    elif edge_type == 'keyword':\n",
    "        attrs['type_id'] = 1\n",
    "    elif edge_type == 'semantic':\n",
    "        attrs['type_id'] = 2\n",
    "    elif edge_type == 'query':\n",
    "        attrs['type_id'] = 3\n",
    "    attrs.update(kwargs)\n",
    "    G.add_edge(u, v, **attrs)\n",
    "    return G\n",
    "\n",
    "###########################\n",
    "# Graph & Embedding Construction\n",
    "###########################\n",
    "def build_optimized_graph(context, query=None, semantic_threshold=0.6, device=None):\n",
    "    if device is None:\n",
    "        device = preprocess_device\n",
    "        \n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "    G = nx.Graph()\n",
    "    titles = [title for title, _ in context]\n",
    "    texts = [\" \".join(text) if isinstance(text, list) else text for _, text in context]\n",
    "    \n",
    "    for title in titles:\n",
    "        G.add_node(title)\n",
    "        \n",
    "    with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
    "        with torch.no_grad():\n",
    "            batch_size = 32\n",
    "            all_embeddings = []\n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch_texts = texts[i:i+batch_size]\n",
    "                batch_embeddings = model.encode(batch_texts, convert_to_tensor=True, device=device)\n",
    "                all_embeddings.append(batch_embeddings.cpu())\n",
    "            embeddings = torch.cat(all_embeddings, dim=0)\n",
    "            if query is not None:\n",
    "                query_emb = model.encode(query, convert_to_tensor=True, device=device).cpu()\n",
    "                \n",
    "    # Sequential edges: connect passages that are adjacent\n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i+1, min(i+4, len(titles))):\n",
    "            distance = j - i\n",
    "            weight = np.exp(-distance * 0.5)\n",
    "            add_edge_with_schema(G, titles[i], titles[j], edge_type='sequential', weight=weight, distance=distance)\n",
    "    \n",
    "    # Keyword edges based on TF-IDF cosine similarity\n",
    "    try:\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "        X = tfidf.fit_transform(texts)\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        tfidf_sim = cosine_similarity(X)\n",
    "        flat_tfidf = tfidf_sim.flatten()\n",
    "        tfidf_threshold = max(0.15, np.percentile(flat_tfidf, 75))\n",
    "        for i in range(len(titles)):\n",
    "            for j in range(i+1, len(titles)):\n",
    "                if tfidf_sim[i, j] > tfidf_threshold:\n",
    "                    if not G.has_edge(titles[i], titles[j]):\n",
    "                        add_edge_with_schema(G, titles[i], titles[j], edge_type='keyword', weight=tfidf_sim[i, j], keyword_sim=tfidf_sim[i, j])\n",
    "                    else:\n",
    "                        G[titles[i]][titles[j]]['keyword_sim'] = tfidf_sim[i, j]\n",
    "                        G[titles[i]][titles[j]]['weight'] = max(G[titles[i]][titles[j]]['weight'], tfidf_sim[i, j])\n",
    "    except Exception as e:\n",
    "        print(f\"TF-IDF edge creation failed: {e}\")\n",
    "        \n",
    "    # Semantic similarity edges using cosine from SentenceTransformer embeddings\n",
    "    sim_matrix = torch.zeros((len(titles), len(titles)))\n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i+1, len(titles)):\n",
    "            sim = util.pytorch_cos_sim(embeddings[i], embeddings[j]).item()\n",
    "            sim_matrix[i, j] = sim\n",
    "            sim_matrix[j, i] = sim\n",
    "    \n",
    "    if query is not None:\n",
    "        query_sims = torch.zeros(len(titles))\n",
    "        for i in range(len(titles)):\n",
    "            query_sims[i] = util.pytorch_cos_sim(query_emb, embeddings[i]).item()\n",
    "        if query_sims.max() > query_sims.min():\n",
    "            query_sims = (query_sims - query_sims.min()) / (query_sims.max() - query_sims.min())\n",
    "    \n",
    "    flat_sims = sim_matrix.flatten()[sim_matrix.flatten() > 0]\n",
    "    if len(flat_sims) > 0:\n",
    "        adapt_threshold = max(semantic_threshold, flat_sims.mean() + 0.5 * flat_sims.std())\n",
    "    else:\n",
    "        adapt_threshold = semantic_threshold\n",
    "        \n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i+1, len(titles)):\n",
    "            base_sim = sim_matrix[i, j].item()\n",
    "            if query is not None:\n",
    "                relevance_boost = query_sims[i] * query_sims[j] * 0.2\n",
    "                adjusted_sim = base_sim + relevance_boost\n",
    "            else:\n",
    "                adjusted_sim = base_sim\n",
    "            if adjusted_sim > adapt_threshold:\n",
    "                if not G.has_edge(titles[i], titles[j]):\n",
    "                    add_edge_with_schema(G, titles[i], titles[j], edge_type='semantic', weight=adjusted_sim, semantic_sim=base_sim)\n",
    "                else:\n",
    "                    G[titles[i]][titles[j]]['semantic_sim'] = base_sim\n",
    "                    G[titles[i]][titles[j]]['weight'] = max(G[titles[i]][titles[j]]['weight'], adjusted_sim)\n",
    "                    \n",
    "    # Query edges (if query provided)\n",
    "    if query is not None:\n",
    "        query_node = \"__QUERY__\"\n",
    "        G.add_node(query_node)\n",
    "        for i, title in enumerate(titles):\n",
    "            sim = query_sims[i].item()\n",
    "            if sim > 0.4:\n",
    "                add_edge_with_schema(G, query_node, title, edge_type='query', weight=sim, query_sim=sim)\n",
    "    \n",
    "    edge_counts = {etype:0 for etype in [\"sequential\", \"keyword\", \"semantic\", \"query\"]}\n",
    "    for _, _, data in G.edges(data=True):\n",
    "        etype = data.get('type', 'unknown')\n",
    "        edge_counts[etype] += 1\n",
    "    G.graph['edge_counts'] = edge_counts\n",
    "    G.graph['node_count'] = len(G.nodes)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return G, embeddings, titles\n",
    "\n",
    "###########################\n",
    "# Fast Cached Embedder\n",
    "###########################\n",
    "class FastCachedEmbedder:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n",
    "        if device is None:\n",
    "            device = preprocess_device\n",
    "        self.model = SentenceTransformer(model_name).to(device)\n",
    "        self.device = device\n",
    "        self.passage_cache = {}\n",
    "        self.question_cache = {}\n",
    "        self.use_amp = (device.type == \"cuda\")\n",
    "        \n",
    "    def encode_passages(self, texts, batch_size=32):\n",
    "        to_encode = [t for t in texts if t not in self.passage_cache]\n",
    "        if to_encode:\n",
    "            all_embeddings = []\n",
    "            with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "                with torch.no_grad():\n",
    "                    for i in range(0, len(to_encode), batch_size):\n",
    "                        batch_texts = to_encode[i:i+batch_size]\n",
    "                        batch_embs = self.model.encode(batch_texts, convert_to_tensor=True, device=self.device)\n",
    "                        all_embeddings.append(batch_embs.cpu())\n",
    "            if all_embeddings:\n",
    "                all_embs = torch.cat(all_embeddings, dim=0)\n",
    "                for text, emb in zip(to_encode, all_embs):\n",
    "                    self.passage_cache[text] = emb\n",
    "        return [torch.tensor(self.passage_cache[t], dtype=torch.float) if not torch.is_tensor(self.passage_cache[t]) \n",
    "                else self.passage_cache[t] for t in texts]\n",
    "    \n",
    "    def encode_question(self, question):\n",
    "        if question not in self.question_cache:\n",
    "            with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "                with torch.no_grad():\n",
    "                    self.question_cache[question] = self.model.encode(question, convert_to_tensor=True, device=self.device).cpu()\n",
    "        q = self.question_cache[question]\n",
    "        return q if torch.is_tensor(q) else torch.tensor(q, dtype=torch.float)\n",
    "\n",
    "###########################\n",
    "# Graph Data Creation\n",
    "###########################\n",
    "def create_graph_data(question, context, supporting_titles, embedder):\n",
    "    titles = [title for title, _ in context]\n",
    "    texts = [\" \".join(text) if isinstance(text, list) else text for _, text in context]\n",
    "    embeddings = embedder.encode_passages(texts)\n",
    "    G, _, _ = build_optimized_graph(context, query=question, device=embedder.device)\n",
    "    node_features = {}\n",
    "    for i, title in enumerate(titles):\n",
    "        emb = embeddings[i]\n",
    "        if not torch.is_tensor(emb):\n",
    "            emb = torch.tensor(emb, dtype=torch.float)\n",
    "        node_features[title] = emb\n",
    "    if \"__QUERY__\" in G.nodes():\n",
    "        query_emb = embedder.encode_question(question)\n",
    "        if not torch.is_tensor(query_emb):\n",
    "            query_emb = torch.tensor(query_emb, dtype=torch.float)\n",
    "        node_features[\"__QUERY__\"] = query_emb\n",
    "    node_order = list(G.nodes())\n",
    "    data = from_networkx(G)\n",
    "    data.x = torch.stack([node_features[n] for n in node_order if n in node_features])\n",
    "    data.edge_index, _ = add_self_loops(data.edge_index)\n",
    "    passage_nodes = [n for n in node_order if n != \"__QUERY__\"]\n",
    "    data.titles = passage_nodes\n",
    "    data.supporting_titles = supporting_titles\n",
    "    data.question = question\n",
    "    data.query_idx = node_order.index(\"__QUERY__\") if \"__QUERY__\" in node_order else None\n",
    "    data.num_passage_nodes = len(passage_nodes)\n",
    "    if \"__QUERY__\" in node_features:\n",
    "        data.question_embedding = node_features[\"__QUERY__\"]\n",
    "    else:\n",
    "        data.question_embedding = embedder.encode_question(question)\n",
    "    return data\n",
    "\n",
    "###########################\n",
    "# Dataset Builder\n",
    "###########################\n",
    "def build_dataset(df, embedder, max_samples=None, save_path=None, load_path=None):\n",
    "    if load_path and os.path.exists(save_path):\n",
    "        try:\n",
    "            with open(save_path, 'rb') as f:\n",
    "                print(f\"Loaded dataset from {save_path}\")\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dataset: {e}\")\n",
    "    if max_samples:\n",
    "        df = df.iloc[:max_samples]\n",
    "    dataset = []\n",
    "    dataset_type = save_path.split('_')[0] if save_path else \"unknown\"\n",
    "    print(f\"Building {dataset_type} dataset ({len(df)} examples)...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Building {dataset_type} dataset\"):\n",
    "        try:\n",
    "            question = row['question']\n",
    "            context = [tuple(x) for x in row['context']]\n",
    "            supporting = [x[0] for x in row['supporting_facts']] if ('supporting_facts' in row and row['supporting_facts']) else []\n",
    "            graph = create_graph_data(question, context, supporting, embedder)\n",
    "            if graph:\n",
    "                dataset.append(graph)\n",
    "            if idx % 50 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing example {idx}: {e}\")\n",
    "            continue\n",
    "    if save_path:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(dataset, f)\n",
    "        print(f\"Saved dataset to {save_path}\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Built {dataset_type} dataset with {len(dataset)} examples\")\n",
    "    return dataset\n",
    "\n",
    "###########################\n",
    "# Improved GNN Model (BetterGNN)\n",
    "###########################\n",
    "class BetterGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.input_proj = nn.Linear(in_channels, hidden_channels)\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.residuals = nn.ModuleList()\n",
    "        # Use GATConv for attention aggregation.\n",
    "        for i in range(num_layers):\n",
    "            conv = GATConv(hidden_channels, hidden_channels, heads=1, dropout=dropout, concat=False)\n",
    "            self.convs.append(conv)\n",
    "            self.norms.append(nn.LayerNorm(hidden_channels))\n",
    "            # Residual mapping.\n",
    "            self.residuals.append(nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.out_proj = nn.Linear(hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.input_proj(x)\n",
    "        out = x\n",
    "        for conv, norm, res in zip(self.convs, self.norms, self.residuals):\n",
    "            residual = out\n",
    "            out = conv(out, edge_index)\n",
    "            out = norm(out)\n",
    "            out = F.relu(out)\n",
    "            out = out + res(residual)  # Skip connection\n",
    "            out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = self.out_proj(out)\n",
    "        return out\n",
    "\n",
    "###########################\n",
    "# Training & Evaluation Functions for GNN with Combined Loss\n",
    "###########################\n",
    "def train_model(model, train_dataset, eval_dataset, optimizer, scheduler,\n",
    "                epochs=50, device='cpu', sim_scale=20.0, margin=0.2, lambda_loss=0.5):\n",
    "    # Combine Margin Ranking Loss and BCE Loss\n",
    "    margin_loss_fn = nn.MarginRankingLoss(margin=margin)\n",
    "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            node_reps = model(batch)\n",
    "            loss = 0.0\n",
    "            for i in range(batch.num_graphs):\n",
    "                node_mask = (batch.batch == i)\n",
    "                reps = node_reps[node_mask]\n",
    "                titles = batch.titles[i]\n",
    "                supporting_titles = batch.supporting_titles[i]\n",
    "                num_passage_nodes = batch.num_passage_nodes[i]\n",
    "                query_idx = batch.query_idx[i] if batch.query_idx[i] is not None else num_passage_nodes\n",
    "                passage_reps = reps[:num_passage_nodes]\n",
    "                query_rep = reps[query_idx]\n",
    "                if query_rep.dim() == 1:\n",
    "                    query_rep = query_rep.unsqueeze(0)\n",
    "                sims = sim_scale * F.cosine_similarity(query_rep, passage_reps, dim=1)\n",
    "                # BCE loss target: 1 for positive passages, 0 for negatives.\n",
    "                labels = torch.tensor([1.0 if t in supporting_titles else 0.0 for t in titles],\n",
    "                                      dtype=torch.float, device=device)\n",
    "                bce_loss = bce_loss_fn(sims, labels)\n",
    "                # Margin ranking loss over all positive-negative pairs.\n",
    "                pos_indices = [j for j, t in enumerate(titles) if t in supporting_titles]\n",
    "                neg_indices = [j for j, t in enumerate(titles) if t not in supporting_titles]\n",
    "                if len(pos_indices) > 0 and len(neg_indices) > 0:\n",
    "                    pos_scores = sims[pos_indices].unsqueeze(1)\n",
    "                    neg_scores = sims[neg_indices].unsqueeze(0)\n",
    "                    target = torch.ones_like(pos_scores)\n",
    "                    mr_loss = margin_loss_fn(pos_scores, neg_scores, target)\n",
    "                else:\n",
    "                    mr_loss = torch.tensor(0.0, device=device)\n",
    "                combined_loss = lambda_loss * mr_loss + (1 - lambda_loss) * bce_loss\n",
    "                loss += combined_loss\n",
    "            loss = loss / batch.num_graphs\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        dev_f1, dev_mrr = evaluate_model(model, eval_dataset, device=device, top_k=5, sim_scale=sim_scale)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} Loss: {avg_loss:.4f}, Eval F1: {dev_f1:.4f}, Eval MRR: {dev_mrr:.4f}\")\n",
    "        \n",
    "def evaluate_model(model, dataset, device='cpu', top_k=5, sim_scale=20.0):\n",
    "    model.eval()\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    all_f1, all_mrr = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            node_reps = model(batch)\n",
    "            for i in range(batch.num_graphs):\n",
    "                node_mask = (batch.batch == i)\n",
    "                reps = node_reps[node_mask]\n",
    "                titles = batch.titles[i]\n",
    "                supporting_titles = batch.supporting_titles[i]\n",
    "                num_passage_nodes = batch.num_passage_nodes[i]\n",
    "                query_idx = batch.query_idx[i] if batch.query_idx[i] is not None else num_passage_nodes\n",
    "                passage_reps = reps[:num_passage_nodes]\n",
    "                query_rep = reps[query_idx]\n",
    "                if query_rep.dim() == 1:\n",
    "                    query_rep = query_rep.unsqueeze(0)\n",
    "                sims = sim_scale * F.cosine_similarity(query_rep, passage_reps, dim=1)\n",
    "                sorted_indices = torch.argsort(sims, descending=True)\n",
    "                rr = 0.0\n",
    "                for rank, idx in enumerate(sorted_indices, start=1):\n",
    "                    if titles[idx] in supporting_titles:\n",
    "                        rr = 1.0 / rank\n",
    "                        break\n",
    "                all_mrr.append(rr)\n",
    "                retrieved = [titles[idx] for idx in sorted_indices[:top_k]]\n",
    "                true_positives = len(set(retrieved) & set(supporting_titles))\n",
    "                precision = true_positives / top_k if top_k > 0 else 0.0\n",
    "                recall = true_positives / len(supporting_titles) if len(supporting_titles) > 0 else 0.0\n",
    "                f1 = 2 * precision * recall / (precision + recall) if (precision+recall) > 0 else 0.0\n",
    "                all_f1.append(f1)\n",
    "    avg_f1 = sum(all_f1) / len(all_f1) if all_f1 else 0.0\n",
    "    avg_mrr = sum(all_mrr) / len(all_mrr) if all_mrr else 0.0\n",
    "    return avg_f1, avg_mrr\n",
    "\n",
    "###########################\n",
    "# Baseline Evaluation Functions (BM25 and DPR)\n",
    "###########################\n",
    "def evaluate_baseline_bm25(df, top_k=5):\n",
    "    total_f1, total_mrr = 0.0, 0.0\n",
    "    n = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        context = row['context']\n",
    "        supporting = [fact[0] for fact in row['supporting_facts']] if 'supporting_facts' in row and row['supporting_facts'] else []\n",
    "        passages = []\n",
    "        titles = []\n",
    "        for title, sentences in context:\n",
    "            merged = \" \".join(sentences) if isinstance(sentences, list) else sentences\n",
    "            passages.append(merged.lower())\n",
    "            titles.append(title)\n",
    "        if len(passages) == 0:\n",
    "            continue\n",
    "        bm25 = BM25Okapi([doc.split() for doc in passages])\n",
    "        scores = bm25.get_scores(question.lower().split())\n",
    "        ranked_indices = np.argsort(scores)[::-1]\n",
    "        rr = 0.0\n",
    "        for rank, idx in enumerate(ranked_indices, start=1):\n",
    "            if titles[idx] in supporting:\n",
    "                rr = 1.0 / rank\n",
    "                break\n",
    "        retrieved = [titles[idx] for idx in ranked_indices[:top_k]]\n",
    "        true_positives = len(set(retrieved) & set(supporting))\n",
    "        precision = true_positives / top_k if top_k > 0 else 0.0\n",
    "        recall = true_positives / len(supporting) if len(supporting) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision+recall) if (precision+recall) > 0 else 0.0\n",
    "        total_f1 += f1\n",
    "        total_mrr += rr\n",
    "        n += 1\n",
    "    return total_f1/n if n>0 else 0.0, total_mrr/n if n>0 else 0.0\n",
    "\n",
    "def evaluate_baseline_dpr(df, model_dpr, top_k=5):\n",
    "    total_f1, total_mrr = 0.0, 0.0\n",
    "    n = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        context = row['context']\n",
    "        supporting = [fact[0] for fact in row['supporting_facts']] if 'supporting_facts' in row and row['supporting_facts'] else []\n",
    "        passages = []\n",
    "        titles = []\n",
    "        for title, sentences in context:\n",
    "            merged = \" \".join(sentences) if isinstance(sentences, list) else sentences\n",
    "            passages.append(merged)\n",
    "            titles.append(title)\n",
    "        if len(passages) == 0:\n",
    "            continue\n",
    "        q_emb = model_dpr.encode([question], convert_to_tensor=True)\n",
    "        p_embs = model_dpr.encode(passages, convert_to_tensor=True)\n",
    "        sims = F.cosine_similarity(q_emb, p_embs)\n",
    "        sims = sims.cpu().numpy()\n",
    "        ranked_indices = np.argsort(sims)[::-1]\n",
    "        rr = 0.0\n",
    "        for rank, idx in enumerate(ranked_indices, start=1):\n",
    "            if titles[idx] in supporting:\n",
    "                rr = 1.0 / rank\n",
    "                break\n",
    "        retrieved = [titles[idx] for idx in ranked_indices[:top_k]]\n",
    "        true_positives = len(set(retrieved) & set(supporting))\n",
    "        precision = true_positives / top_k if top_k > 0 else 0.0\n",
    "        recall = true_positives / len(supporting) if len(supporting) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision+recall) if (precision+recall) > 0 else 0.0\n",
    "        total_f1 += f1\n",
    "        total_mrr += rr\n",
    "        n += 1\n",
    "    return total_f1/n if n>0 else 0.0, total_mrr/n if n>0 else 0.0\n",
    "\n",
    "###########################\n",
    "# Hyperparameter Tuning for GNN\n",
    "###########################\n",
    "def tune_results(train_dataset, dev_dataset, hyperparams, base_epochs=10):\n",
    "    best_f1 = -1.0\n",
    "    best_config = None\n",
    "    results = []\n",
    "    for margin in hyperparams.get(\"margin\", [0.2]):\n",
    "        for sim_scale in hyperparams.get(\"sim_scale\", [10.0]):\n",
    "            print(f\"Tuning with margin={margin}, sim_scale={sim_scale}\")\n",
    "            model = BetterGNN(384, 256, 256, num_layers=3, dropout=0.3).to(main_device)\n",
    "            optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "            train_model(model, train_dataset, dev_dataset, optimizer, scheduler,\n",
    "                        epochs=base_epochs, device=main_device, sim_scale=sim_scale, margin=margin)\n",
    "            eval_f1, eval_mrr = evaluate_model(model, dev_dataset, device=main_device, top_k=5, sim_scale=sim_scale)\n",
    "            print(f\"Config margin={margin}, sim_scale={sim_scale}: Eval F1: {eval_f1:.4f}, Eval MRR: {eval_mrr:.4f}\\n\")\n",
    "            results.append(((margin, sim_scale), eval_f1, eval_mrr))\n",
    "            if eval_f1 > best_f1:\n",
    "                best_f1 = eval_f1\n",
    "                best_config = {\"margin\": margin, \"sim_scale\": sim_scale}\n",
    "    print(\"Tuning results:\")\n",
    "    for (margin, sim_scale), f1, mrr in results:\n",
    "        print(f\"Margin: {margin}, SIM_SCALE: {sim_scale} -> F1: {f1:.4f}, MRR: {mrr:.4f}\")\n",
    "    print(f\"Best configuration: {best_config} with F1: {best_f1:.4f}\")\n",
    "    return best_config, results\n",
    "\n",
    "###########################\n",
    "# Main Routine\n",
    "###########################\n",
    "def main():\n",
    "    # Use 1500 samples for training and 300 for dev for final training; \n",
    "    # for final reported experiments, you might later use full data.\n",
    "    embedder = FastCachedEmbedder(model_name='all-MiniLM-L6-v2', device=main_device)\n",
    "    train_dataset = build_dataset(train_df, embedder=embedder, max_samples=1500, save_path=\"train_dataset.pkl\")\n",
    "    dev_dataset = build_dataset(dev_df, embedder=embedder, max_samples=300, save_path=\"dev_dataset.pkl\")\n",
    "    \n",
    "    # Baseline evaluations on dev (use first 20 examples for quick comparison)\n",
    "    dev_df_small = dev_df.iloc[:20]\n",
    "    \n",
    "    # Tuning hyperparameters over our BetterGNN architecture.\n",
    "    hyperparams = {\"margin\": [0.1, 0.2], \"sim_scale\": [10.0, 20.0, 30.0]}\n",
    "    best_config, tuning_results = tune_results(train_dataset, dev_dataset, hyperparams, base_epochs=10)\n",
    "    best_margin = best_config[\"margin\"]\n",
    "    best_sim_scale = best_config[\"sim_scale\"]\n",
    "    \n",
    "    # Final training with improved BetterGNN architecture.\n",
    "    model = BetterGNN(384, 256, 256, num_layers=3, dropout=0.3).to(main_device)\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "    \n",
    "    print(\"Starting final training with best hyperparameters for BetterGNN...\")\n",
    "    train_model(model, train_dataset, dev_dataset, optimizer, scheduler,\n",
    "                epochs=50, device=main_device, sim_scale=best_sim_scale, margin=best_margin, lambda_loss=0.5)\n",
    "    \n",
    "    final_f1, final_mrr = evaluate_model(model, dev_dataset, device=main_device, top_k=5, sim_scale=best_sim_scale)\n",
    "    print(f\"Final GNN Eval F1: {final_f1:.4f}, Final GNN Eval MRR: {final_mrr:.4f}\")\n",
    "    \n",
    "    # Baseline BM25 evaluation:\n",
    "    bm25_f1, bm25_mrr = evaluate_baseline_bm25(dev_df_small, top_k=5)\n",
    "    print(f\"BM25 Baseline Eval F1: {bm25_f1:.4f}, Eval MRR: {bm25_mrr:.4f}\")\n",
    "    \n",
    "    # Baseline DPR evaluation:\n",
    "    model_dpr = SentenceTransformer('all-MiniLM-L6-v2', device=main_device)\n",
    "    dpr_f1, dpr_mrr = evaluate_baseline_dpr(dev_df_small, model_dpr, top_k=5)\n",
    "    print(f\"DPR Baseline Eval F1: {dpr_f1:.4f}, Eval MRR: {dpr_mrr:.4f}\")\n",
    "    \n",
    "    # Optional LLM Generation using T5:\n",
    "    from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "    t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(main_device)\n",
    "    t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    sample = dev_dataset[0]\n",
    "    sample = sample.to(main_device)\n",
    "    with torch.no_grad():\n",
    "        sample_rep = model(sample)\n",
    "    titles = sample.titles\n",
    "    num_passage_nodes = sample.num_passage_nodes\n",
    "    query_idx = sample.query_idx if sample.query_idx is not None else num_passage_nodes\n",
    "    passage_reps = sample_rep[:num_passage_nodes]\n",
    "    query_rep = sample_rep[query_idx]\n",
    "    if query_rep.dim() == 1:\n",
    "        query_rep = query_rep.unsqueeze(0)\n",
    "    sims = best_sim_scale * F.cosine_similarity(query_rep, passage_reps, dim=1)\n",
    "    sorted_indices = torch.argsort(sims, descending=True)\n",
    "    top_passages = [titles[idx] for idx in sorted_indices[:5]]\n",
    "    answer = generate_answer(sample.question, top_passages, t5_model, t5_tokenizer)\n",
    "    print(\"LLM Generated Answer:\", answer)\n",
    "    \n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(f\"BM25 Baseline:    F1: {bm25_f1:.4f}, MRR: {bm25_mrr:.4f}\")\n",
    "    print(f\"DPR Baseline:     F1: {dpr_f1:.4f}, MRR: {dpr_mrr:.4f}\")\n",
    "    print(f\"BetterGNN Approach: F1: {final_f1:.4f}, MRR: {final_mrr:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ee52b-ad5c-48ea-bcce-1dc2fc2af1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
